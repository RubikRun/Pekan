----------
03.04.2025
----------

Officially starting work on v0.2.
Let's follow the list of features in
    plan_0004.txt

{
Let's tart with the event system. That's a big one.
I will use the following commits from Hazel Engine as reference.
    https://github.com/TheCherno/Hazel/commit/34df41651fe88041540f20df845a70642359dc17
    https://github.com/TheCherno/Hazel/commit/30516ad7109b016213eb732f14e1c7061c1db603

As a first step I will copy most of it, and just integrate it into Pekan,
to see how it works and to see if I like it.

Let's create a new directory
    Events
under
    src/PekanCore
Inside of it create the following header files
    WindowEvent.h
    Event.h
    KeyEvent.h
    MouseEvent.h
Add them to project PekanCore in the root CMake file.
Now I will copy code from the corresponding files in this Hazel commit
    https://github.com/TheCherno/Hazel/commit/34df41651fe88041540f20df845a70642359dc17
and integrate it into Pekan.
Done.

Now we have all relevant event types as classes.
Let's implement the actual event system using those classes.
The bottomline is we need to call these GLFW functions in PekanEngine
    glfwSetKeyCallback(s_window, ...);
    glfwSetCursorPosCallback(s_window, ...);
    glfwSetScrollCallback(s_window, ...);
    glfwSetMouseButtonCallback(s_window, ...);
    glfwSetWindowSizeCallback(s_window, ...);
    glfwSetWindowCloseCallback(s_window, ...);
and pass some appropriate functions as second parameters.
The functions that we will pass there will be called whenever an event of the given type occurs.

Let's create a new class
    EventHandler
in
    Event.h
and create static functions that we will use to pass as seconds parameters to the GLFW functions
    static void handleKeyEvent(GLFWwindow* window, int key, int scancode, int action, int mods);
    static void handleMouseMovedEvent(GLFWwindow* window, double xPos, double yPos);
    static void handleMouseScrolledEvent(GLFWwindow* window, double xOffset, double yOffset);
    static void handleMouseButtonEvent(GLFWwindow* window, int button, int action, int mods);
    static void handleWindowResizedEvent(GLFWwindow* window, int width, int height);
    static void handleWindowClosedEvent(GLFWwindow* window);
Then we can do this in PekanEngine.cpp
    glfwSetKeyCallback(s_window, EventHandler::handleKeyEvent);
    glfwSetCursorPosCallback(s_window, EventHandler::handleMouseMovedEvent);
    glfwSetScrollCallback(s_window, EventHandler::handleMouseScrolledEvent);
    glfwSetMouseButtonCallback(s_window, EventHandler::handleMouseButtonEvent);
    glfwSetWindowSizeCallback(s_window, EventHandler::handleWindowResizedEvent);
    glfwSetWindowCloseCallback(s_window, EventHandler::handleWindowClosedEvent);

Okay, then what? These 6 functions will be called whenever an event of their specific type occurs.
What should these functions do?
What should happen when a key is pressed, for example?
Well, we need a way for client applications to say what happens when a key is pressed.
Client applications need to be able to register a custom callback function to be called whenever a key is pressed.
Furthermore, we have more event types than just these 6 functions. We may have a couple of event types for each of these 6 functions.
For example, when ANY key event occurs this function
    handleKeyEvent()
will be called, but this may correspond either to a KeyPressedEvent or a KeyReleasedEvent.
So, client applications need to be able to register a custom callback function for each of OUR event types (8 in total).
For example, they need to be able to register a callback for when a key is pressed and another callback for when a key is released.
Let's add these 8 functions
    static inline void registerKeyPressedCallback(const KeyPressedCallback& callback) { s_keyPressedCallbacks.push_back(callback); }
    static inline void registerKeyReleasedCallback(const KeyReleasedCallback& callback) { s_keyReleasedCallbacks.push_back(callback); }
    static inline void registerMouseMovedCallback(const MouseMovedCallback& callback) { s_mouseMovedCallbacks.push_back(callback); }
    static inline void registerMouseScrolledCallback(const MouseScrolledCallback& callback) { s_mouseScrolledCallbacks.push_back(callback); }
    static inline void registerMouseButtonPressedCallback(const MouseButtonPressedCallback& callback) { s_mouseButtonPressedCallbacks.push_back(callback); }
    static inline void registerMouseButtonReleasedCallback(const MouseButtonReleasedCallback& callback) { s_mouseButtonReleasedCallbacks.push_back(callback); }
    static inline void registerWindowResizedCallback(const WindowResizedCallback& callback) { s_windowResizedCallbacks.push_back(callback); }
    static inline void registerWindowClosedCallback(const WindowClosedCallback& callback) { s_windowClosedCallbacks.push_back(callback); }
where
    typedef std::function<bool(KeyPressedEvent&)> KeyPressedCallback;
    typedef std::function<bool(KeyReleasedEvent&)> KeyReleasedCallback;
    typedef std::function<bool(MouseMovedEvent&)> MouseMovedCallback;
    typedef std::function<bool(MouseScrolledEvent&)> MouseScrolledCallback;
    typedef std::function<bool(MouseButtonPressedEvent&)> MouseButtonPressedCallback;
    typedef std::function<bool(MouseButtonReleasedEvent&)> MouseButtonReleasedCallback;
    typedef std::function<bool(WindowResizedEvent&)> WindowResizedCallback;
    typedef std::function<bool(WindowClosedEvent&)> WindowClosedCallback;
And what will these 8 functions do?
They will just add the given callback to a list of callbacks corresponding to the specific event type.
So we need 8 lists of callbacks, as members in EventHandler
    static std::vector<KeyPressedCallback> s_keyPressedCallbacks;
    static std::vector<KeyReleasedCallback> s_keyReleasedCallbacks;
    static std::vector<MouseMovedCallback> s_mouseMovedCallbacks;
    static std::vector<MouseScrolledCallback> s_mouseScrolledCallbacks;
    static std::vector<MouseButtonPressedCallback> s_mouseButtonPressedCallbacks;
    static std::vector<MouseButtonReleasedCallback> s_mouseButtonReleasedCallbacks;
    static std::vector<WindowResizedCallback> s_windowResizedCallbacks;
    static std::vector<WindowClosedCallback> s_windowClosedCallbacks;
and each of the register*() functions will just add the callback to the corresponding list, as shown above.
Then, once we have a list of callbacks, we can think about what the handle*() functions should do.
Well, they should call the callbacks.
But to do that, they need to first create an event.
For example, the handleMouseMovedEvent() function needs to construct a MouseMovedEvent, like that
    MouseMovedEvent event = { float(xPos), float(yPos) };
and then it can call the callbacks registered for MouseMovedEvents (the callbacks in s_mouseMovedCallbacks) like that
    for (const MouseMovedCallback& callback : s_mouseMovedCallbacks)
    {
        if (callback(event))
        {
            event.m_handled = true;
            break;
        }
    }
(The logic behind the if statement and setting m_handled is explained below, for now only notice that we're calling callback(event))
Constructing the event of the specific type will be different in the different handle*() functions,
but the for-loop for calling the callbacks will be exactly the same,
so we can create a template function for that
    template <typename EventT, typename CallbackT>
    static void handleEvent(EventT& event, const std::vector<CallbackT>& callbacks)
    {
        for (const CallbackT& callback : callbacks)
        {
            if (callback(event))
            {
                event.m_handled = true;
                break;
            }
        }
    }
Now the implementation of handleMouseMovedEvent() boils down to just this
    void EventHandler::handleMouseMovedEvent(GLFWwindow* window, double xPos, double yPos)
    {
        MouseMovedEvent event = { float(xPos), float(yPos) };
        handleEvent(event, s_mouseMovedCallbacks);
    }
Neat!
It's a bit more complicated in the handle*() functions that need to differentiate between multiple different event types.
For example handleKeyEvent() may construct either a KeyPressedEvent or a KeyReleasedEvent() depending on the value of the "action" parameter.
Those details are not important, and quite straightforward, so leaving it at that.

One final thing to explain here is why don't we just call
    callback(event)
in the handleEvent() template function.
Why do we do
    if (callback(event))
    {
        event.m_handled = true;
        break;
    }
All callbacks here return a bool which means whether the event was handled, or just skipped.
This might make more sense especially when considering multiple layers.
For example if we have a game where clicking the mouse makes the player jump,
this game world will be on one layer, but on top of that we may have another layer with GUI,
where clicking the mouse has another meaning.
So in that case we would have 2 callbacks registered in s_keyPressedCallbacks
and if one of them handles the event we want to NOT call the callback of the other layer.

That's about it. That's the event system.

Let's test it in Demo03.
Let's create callback functions for each event type, in Snake.cpp
    bool onKeyPressed(Pekan::KeyPressedEvent& event);
    bool onKeyReleased(Pekan::KeyReleasedEvent& event);
    bool onMouseMoved(Pekan::MouseMovedEvent& event);
    bool onMouseScrolled(Pekan::MouseScrolledEvent& event);
    bool onMouseButtonPressed(Pekan::MouseButtonPressedEvent& event);
    bool onMouseButtonReleased(Pekan::MouseButtonReleasedEvent& event);
    bool onWindowResized(Pekan::WindowResizedEvent& event);
    bool onWindowClosed(Pekan::WindowClosedEvent& event);
and let's implement them to just log the event using PekanLogger
    bool Snake::onKeyPressed(KeyPressedEvent& event)
    {
        PK_LOG_INFO(event, "Boris");
        return true;
    }
    ...
We need to register these callbacks using the EventHandler. We can do that in Snake's create() function, like that
    EventHandler::registerKeyPressedCallback(std::bind(&Snake::onKeyPressed, this, std::placeholders::_1));
    EventHandler::registerKeyReleasedCallback(std::bind(&Snake::onKeyReleased, this, std::placeholders::_1));
    EventHandler::registerMouseMovedCallback(std::bind(&Snake::onMouseMoved, this, std::placeholders::_1));
    EventHandler::registerMouseScrolledCallback(std::bind(&Snake::onMouseScrolled, this, std::placeholders::_1));
    EventHandler::registerMouseButtonPressedCallback(std::bind(&Snake::onMouseButtonPressed, this, std::placeholders::_1));
    EventHandler::registerMouseButtonReleasedCallback(std::bind(&Snake::onMouseButtonReleased, this, std::placeholders::_1));
    EventHandler::registerWindowResizedCallback(std::bind(&Snake::onWindowResized, this, std::placeholders::_1));
    EventHandler::registerWindowClosedCallback(std::bind(&Snake::onWindowClosed, this, std::placeholders::_1));
Okay, it works!
Pretty nice.

Final note, I copied only the event classes from Hazel Engine, the EventHandler was my own creation.

Event system done.
}

----------
07.04.2025
----------

{
Now that we have the event system, it'd be good to also allow applications to ask for the current state of things,
for example where the mouse is currently, or what the resolution is currently, or is a given key pressed at the moment.
I wouldn't call this a "part" of the event system, but it's definitely related, and more like a complementary feature.

So what we need basically, is something similar to these 4 temporary functions that we have right now in PekanEngine
    static bool isKeyPressed_W();
    static bool isKeyPressed_A();
    static bool isKeyPressed_S();
    static bool isKeyPressed_D();
I made those functions to allow the snake game (Demo03) to work before having the event system.
We need similar functions now, but done better, and covering everything that the event system covers.

Let's start with key events - KeyPressedEvent and KeyReleasedEvent.
We can cover those with 3 functions
    static bool isKeyPressed(int key);
    static bool isKeyReleased(int key);
    static bool isKeyRepeating(int key);
Next type of event to cover is MouseMovedEvent.
We can cover that with 1 function
    static glm::vec2 getMousePosition();
Next is MouseScrolledEvent - we will not cover that because it makes no sense to ask for the current mouse scroll
(and because GLFW doesn't support it)
Next is MouseButtonPressed and MouseButtonReleased. We need 2 functions
    static bool isMouseButtonPressed(bool leftOrRight);
    static bool isMouseButtonReleased(bool leftOrRight);
And I think the final one is WindowResizedEvent. We need 1 function
    static glm::ivec2 getWindowResolution();
That's it.
Done.
}

----------
11.04.2025
----------

{
Next feature to implement is layers.
I will use as reference this commit from Hazel Engine
    https://github.com/TheCherno/Hazel/commit/5bd809312a266c23d13d84dcd08a833a526aa264

Ended up not using much, I only copied and changed Layer and LayerStack,
everything else I had to do on my own.

I did the whole thing at once, without taking notes, so here's a sum up:
I'll divide it into 3 parts - layers, init/exit/update/render layers, events in layers.

1. First of all, a layer fundamentally is just something that can be initialized, exited, updated and rendered
    virtual bool init() { return true; }
    virtual void exit() {}
    virtual void update() {}
    virtual void render() {}
It also has a name but that's not important
    std::string m_name;
Then we have a LayerStack which is just a wrapper over a list of layers
    std::vector<Layer*> m_layers;
and it provides iterators for traversing the layer stack forwards and backwards
    std::vector<Layer*>::iterator begin() { return m_layers.begin(); }
    std::vector<Layer*>::iterator end() { return m_layers.end(); }
    std::vector<Layer*>::reverse_iterator rbegin() { return m_layers.rbegin(); }
    std::vector<Layer*>::reverse_iterator rend() { return m_layers.rend(); }
Nothing interesting there.
So how are we going to use layers in Pekan?
Well, scenes and GUI windows will be layers.
We actually don't need the class
    PekanScene
at all, because it's literally just a Layer without any extra functionality.
We still need the class
    PekanGUIWindow
because it has some ImGui-specific functionality in render(), but other than that we'll make it derive from Layer
    class PekanGUIWindow : public Layer

2. Okay, so scenes and GUI windows are layers.
Now what?
Well, currently in PekanApplication we have 2 members for a scene and a GUI window.
We don't want that. We want clients to be able to compose scenes and GUI windows as they wish,
maybe they want multiple scenes on top of each other, or they don't want a GUI window, or they want multiple GUI windows, etc.
So instead of having 2 members for a scene and a GUI window let's have a single LayerStack member
    LayerStack m_layerStack;
and then client applications can configure this stack as they wish in the _init() function, for example like that
    m_layerStack.pushLayer(demoScene);
    m_layerStack.pushLayer(demoGuiWindow);
(Notice that the order of adding the layers is important. Layers added first will be rendered first)
Then the only thing left to do is make PekanApplication work with this layer stack instead of a scene and a GUI window,
so in PekanApplication.cpp in all places where we previously did something with m_scene or m_guiWindow, (init/exit/update/render)
now we need to do it with all layers in the layer stack, like that for example:
    // Update all layers
    for (Layer* layer : m_layerStack)
    {
        if (layer)
        {
            layer->update();
        }
    }
    // Render all layers
    for (Layer* layer : m_layerStack)
    {
        if (layer)
        {
            layer->render();
        }
    }
And finally, we need to update our demos a bit, to configure the layer stack in their _init() functions.
That's it.
Now everything works same as before, but demos can configure layers freely.

3. Trickies part here is making events work with layers.
Currently we have a static class EventHandler and any code can register a callback for any type of event,
which is ok, but it gives too much freedom to clients.
We want to enforce the behavior of events being propagated through layers
in the opposite order of rendering, so that layers drawn last receive events first, because they are on top.
What we want is a way for each layer to specify its own way of handling a given type of event,
and then Pekan will automatically send events to layers in the correct order
and stop sending once a layer has successfully handled an event.
How can we do that?
Well, first we can have virtual functions for each type of event inside of class Layer
    virtual bool onKeyPressed(KeyPressedEvent& event) { return false; }
    virtual bool onKeyReleased(KeyReleasedEvent& event) { return false; }
    virtual bool onMouseMoved(MouseMovedEvent& event) { return false; }
    virtual bool onMouseScrolled(MouseScrolledEvent& event) { return false; }
    virtual bool onMouseButtonPressed(MouseButtonPressedEvent& event) { return false; }
    virtual bool onMouseButtonReleased(MouseButtonReleasedEvent& event) { return false; }
    virtual bool onWindowResized(WindowResizedEvent& event) { return false; }
    virtual bool onWindowClosed(WindowClosedEvent& event) { return false; }
so that derived classes can choose to override some of these functions if they want to react to a specific event.
Then we have to actually call those functions on each layer of the layer stack when an event occurs,
and we have to pass an Event object of the corresponding subtype.
How can we do that?
Well, we already have these 6 static functions in EventHandler
    static void handleKeyEvent(GLFWwindow* window, int key, int scancode, int action, int mods);
    static void handleMouseMovedEvent(GLFWwindow* window, double xPos, double yPos);
    static void handleMouseScrolledEvent(GLFWwindow* window, double xOffset, double yOffset);
    static void handleMouseButtonEvent(GLFWwindow* window, int button, int action, int mods);
    static void handleWindowResizedEvent(GLFWwindow* window, int width, int height);
    static void handleWindowClosedEvent(GLFWwindow* window);
They are directly linked to GLFW by PekanEngine like that:
    glfwSetKeyCallback(s_window, EventHandler::handleKeyEvent);
    glfwSetCursorPosCallback(s_window, EventHandler::handleMouseMovedEvent);
    glfwSetScrollCallback(s_window, EventHandler::handleMouseScrolledEvent);
    glfwSetMouseButtonCallback(s_window, EventHandler::handleMouseButtonEvent);
    glfwSetWindowSizeCallback(s_window, EventHandler::handleWindowResizedEvent);
    glfwSetWindowCloseCallback(s_window, EventHandler::handleWindowClosedEvent);
They construct an Event object of a specific type and call the registered callbacks passing that Event object.
Now we still need to construct the Event objects in the exact same way,
but instead of calling the registered callbacks,
we will call the on*() functions on each layer of the layer stack.
Problem is we don't have access to the layer stack because this EventHandler is all static,
and the layer stack is part of an instance of PekanApplication,
so we'll need to move these handle*() functions to be member functions of PekanApplication
    void handleKeyEvent(int key, int scancode, int action, int mods);
    void handleMouseMovedEvent(double xPos, double yPos);
    void handleMouseScrolledEvent(double xOffset, double yOffset);
    void handleMouseButtonEvent(int button, int action, int mods);
    void handleWindowResizedEvent(int width, int height);
    void handleWindowClosedEvent();
removing the GLFWwindow pointer (we'll see why in a minute)
To implement them in PekanApplication we'll construct the Event objects in the exact same way,
but then instead of calling EventHandler's template function handleEvent()
which works with the registered callbacks,
we'll create a new template function
    static void _dispatchEvent(EventT& event, LayerStack& layerStack, bool (Layer::*onEventFunc)(EventT&))
that calls the on*() functions of each layer of the layer stack until the event is handled.
Then we just call that function with the constructed Event object and give it our application's layer stack
and a pointer to the specific on*() function that it needs to call on the layers. For example, like that:
    MouseMovedEvent event = { float(xPos), float(yPos) };
    _dispatchEvent(event, m_layerStack, &Layer::onMouseMoved);
That's it, that's what the handle*() functions do.
Now the only thing left to do is to connect those handle*() functions to GLFW
and actually make it so that they are called when an event occurs.
We cannot directly connect them to GLFW with the glfwSet*Callback() functions
because they require a callback which is a global/static function
(our handle*() functions are member functions of PekanApplication and so they contain an extra implicit "this" parameter)
What we can do is create yet another set of functions, but this time static in PekanEngine
    static void keyCallback(GLFWwindow* window, int key, int scancode, int action, int mods);
    static void mouseMovedCallback(GLFWwindow* window, double xPos, double yPos);
    static void mouseScrolledCallback(GLFWwindow* window, double xOffset, double yOffset);
    static void mouseButtonCallback(GLFWwindow* window, int button, int action, int mods);
    static void windowResizedCallback(GLFWwindow* window, int width, int height);
    static void windowClosedCallback(GLFWwindow* window);
Now these functions have the exact signature required by the glfwSet*Callback() functions
so we can directly register them to GLFW, like that
    glfwSetKeyCallback(s_window, keyCallback);
    glfwSetCursorPosCallback(s_window, mouseMovedCallback);
    glfwSetScrollCallback(s_window, mouseScrolledCallback);
    glfwSetMouseButtonCallback(s_window, mouseButtonCallback);
    glfwSetWindowSizeCallback(s_window, windowResizedCallback);
    glfwSetWindowCloseCallback(s_window, windowClosedCallback);
And now we reach the root of our problem.
How can we make these static functions call PekanApplication's handle*() functions that are very much non-static,
they are member functions and require a specific instance of a PekanApplication.
Well, we need a static instance of PekanApplication.
We need a mechanism in PekanEngine for a PekanApplication to be "registered"
and kept under a static member variable
    static PekanApplication* s_application;
For that we'll add this new function
    static void registerApplication(PekanApplication* application);
that every PekanApplication will need to call to "register" itself in PekanEngine
before it could be run.
And finally, having this static s_application, we can implement the callbacks as follows:
    void PekanEngine::keyCallback(GLFWwindow* window, int key, int scancode, int action, int mods)
    {
        if (s_application)
        {
            s_application->handleKeyEvent(key, scancode, action, mods);
        }
    }
    ...
That's it.
To sum up, for example looking at a mouse moved event:
Mouse moves -> GLFW calls PekanEngine::mouseMovedCallback()
-> it calls PekanApplication::handleMouseMovedEvent()
-> it constructs a MouseMovedEvent object and calls _dispatchEvent() with it
-> it calls Layer::onMouseMoved() on each layer of the layer stack until the event is handled
-> Layer::onMouseMoved() can be implemented by client to do whatever they want and return true if event is handled
   If not implemented, it will not do anything and just return false, meaning continue to next layer
}

----------
15.04.2025
----------

{
Next feature we'll implement from the list is a simple one:
    Create a way for applications to specify the window's title

Taking a quick look at our current architecture it makes the most sense
that we let applications have a name and then Pekan will automatically set window's title to be that name.
Each specific application will be able to set its name inside of the _init() method,
similar to how it configures the layer stack.
So, to do that, just add this member variable in PekanApplication
    std::string m_name;
and then we can set its value inside of Demo03_Application::_init() like that
    m_name = "Snake Game";
Same for the other demos as well.

Okay, now each application has a name.
We need to use that name for the window's title.
Window's title is set in PekanEngine.cpp like that
    s_window = glfwCreateWindow(width, height, DEFAULT_WINDOW_TITLE, nullptr, nullptr);
So instead of using the constant DEFAULT_WINDOW_TITLE we can use the registered application
    s_application
and use its name.
For that we'll need to have a getter for the name in PekanApplication
    const std::string& getName() const { return m_name; }

Hm but now there's a problem.
The function creating the window is
    PekanEngine::createWindow()
which is called by
    PekanEngine::init()
which is called in
    PekanApplication::init()
before registering the application, so when creating the window we don't yet know the name of our application.
How can we solve this?
We could separate engine initialization from window creation so that PekanApplication
can first initialize the engine, then register itself, and then use the engine to create a window.
But actually a better idea, at least at this point, seems to be merging registering with initialization,
so instead of having a separate function registerApplication() we can just add a parameter to
    PekanEngine::init()
which will be the application. Then init() will handle everything in the correct order.
Let's do that.

Okay, that solved the problem, but now there is another problem of similar nature.
We want to use the member PekanApplication::m_name when calling PekanEngine::init()
but this happens before calling PekanApplication::_init() so the specific application
has not set its name yet.
What we can do is to have a virtual getter for the name that should be implemented by specific applications
if they want to have a name.
So remove the member m_name and change getName() to be
    virtual std::string getName() const { return ""; }
Now in Demo03_Application instead of setting m_name = "Snake Game" inside of _init()
we can implement the getName() function, like that
    std::string getName() const override { return "Snake Game"; }
That's it. Now when PekanEngine calls
    s_application->getName();
this will call the overriden version of getName() and it will return "Snake Game".
If there is no overriden version of getName() then it will call the base version, PekanApplication's version,
which just returns an empty string, and the window's title will default to
    DEFAULT_WINDOW_TITLE

Okay, done.
Looks good. Every application has its name, and window's title corresponds to that name.
}

----------
16.04.2025
----------

{
Next feature we'll look at from the list is also fairly simple (HAHA from future me):
    Limit FPS
Currently PekanEngine enables VSync by default, so FPS is automatically set to be equal to the display's FPS.
That's a good default behavior but we want to allow applications to specify custom FPS.
For that, let's add a member
    double m_fps = 0.0;
to PekanApplication, together with a protected setter
    inline void setFPS(double fps) { m_fps = fps; }
If noone sets FPS it will stay at 0.0 which will mean use VSync.
We will also remove the line that enables VSync in PekanEngine
    glfwSwapInterval(1);
Instead we will add these 2 new functions to PekanEngine
    static void enableVSync();
	static void disableVSync();
for enabling/disabling VSync.
Then in PekanApplication's run() function, before the main loop, we want to enable VSync if there is no FPS specified
    const bool useFPS = (m_fps > 0.0);
    if (!useFPS)
    {
        PekanEngine::enableVSync();
    }
If there is an FPS specified we will need to manually limit our frames to that FPS.
How?
There are a couple of approaches, it's not that straightforward.
We'll add a new class FpsLimiter which will implement the waiting functionality
such that we reach the desired FPS.

I played around with different methods of implementing FpsLimiter. I liked 2 of them.
Couldn't choose between them. I think there's a use case for both, so I'll keep them both.
I called them "Sleep Compensate" and "Wait Blocking".
At the top of FpsLimiter.h you can see a description of what they do and what their pros and cons are.

I decided it will be bad for performance to do any runtime checks for choosing between the 2 implementations
(for example an environment variable, or a member variable in PekanApplication that can be set by derived classes)
So instead I decided to just use a macro for choosing between the 2 implementations at compile time
    #define PEKAN_FPS_LIMITER_IMPL_SLEEP_COMPENSATE 1
    #define PEKAN_FPS_LIMITER_IMPL_WAIT_BLOCKING 0
We'll see later if we need to ship Pekan with both options included.
For now I just wanted to have them both in code, but to use only one at a time.

Looks good. Tested it quite a bit.
Done.
}

----------
17.04.2025
----------

{
I'd like to look at this TO-DO item now:
    Provide a way for applications to specify their way of closing

Currently we are doing this directly inside of PekanApplication's main loop
    // Close window if escape key is pressed
    if (glfwGetKey(window, GLFW_KEY_ESCAPE) == GLFW_PRESS)
    {
        glfwSetWindowShouldClose(window, true);
    }
which is not good. We don't want every application to be closable with the escape key.
We want every application to be able to implement its own closing logic.
So let's remove this from PekanApplication's main loop.
The only demo that needs to be closable by anything other than the X button of the window, is Demo03.
It needs to be closable with the escape key.

Well, we have the event system now so we can definitely use that.
We can make Demo03_Scene react to pressing the escape key, like that
    bool onKeyPressed(Pekan::KeyPressedEvent& event) override;    (Demo03_Scene.h)
and implementing it like
    bool Demo03_Scene::onKeyPressed(Pekan::KeyPressedEvent& event)    (Demo03_Scene.cpp)
    {
        if (event.getKeyCode() == GLFW_KEY_ESCAPE)
        {
            // HERE WE HAVE TO MAKE THE APPLICATION CLOSE
            return true;
        }
        return false;
    }
Okay, that works. It is activated when the escape key is pressed.

Now how do we make the application close? Until now in PekanApplication we did this
    glfwSetWindowShouldClose(window, true);
Obiously we cannot do that from Demo03's code.
PekanApplication should expose an API for closing the application, for example like that
    void stopRunning();    (PekanApplication.h)
and implementing it like
    void PekanApplication::stopRunning()    (PekanApplication.cpp)
    {
        glfwSetWindowShouldClose(PekanEngine::getWindow(), true);
    }
but it'd be good for that API to not be public.
We don't want any code to be able to close an application, we need more control than that.
At first sight it looks like we can just make this new function stopRunning() be protected.
That way only derived applications will be able to call it.
But that's not exactly what we want because it's not the application's logic that will want to close the application,
instead it's the layer's logic. We cannot react to events inside of Demo03_Application,
we can react to events inside of Demo03_Scene.
So we want a layer to be able to close its application.
That's a bit problematic with our current architecture because layers are not aware that an application contains them,
they don't know which one their application is.
Is it a good idea to allow each layer to know its parent application?
Not 100% sure but it seems so. I cannot think of a better solution at the moment,
without complicating things way too much, or changing architecture overall.
So let's go with that.
Let's make every layer know its parent application, by adding a member
    PekanApplication* m_application = nullptr;
to class Layer and let's require an application parameter in Layer's constructor
    Layer(const std::string& name, PekanApplication* application) : m_name(name), m_application(application) {}
Now we need to change a few things, we need to add this extra application parameter to a bunch of other constructors,
but that's okay, easy.

Okay, now every layer knows its parent application.
So it looks like we can make class Layer be a friend to class PekanApplication
    friend class Layer;
and then this function stopRunning() can be called from class Layer.
However, there's a problem. It cannot be called from classes derived from Layer,
and that was the whole point. We want derived classes of Layer to be able to close their application.
It turns out friendship in C++ is not inheritable, so the fact that Layer is a friend to PekanApplication
does NOT mean that derived classes of Layer will be friends to PekanApplication.
There is no way to make derived classes of Layer be friends of PekanApplication.
What we can do instead is to create a protected wrapper API in Layer
    protected:
        void stopRunningApplication();
which calls m_application's stopRunning() function
    if (m_application)
    {
        m_application->stopRunning();
    }
This code is okay because it's part of Layer, which is a friend to PekanApplication.
Then derived classes cannot directly call m_application->stopRunning()
but they can call this protected function stopRunningApplication().
So now we can finally implement Demo03_Scene's closing logic like that
    bool Demo03_Scene::onKeyPressed(Pekan::KeyPressedEvent& event)
    {
        if (event.getKeyCode() == GLFW_KEY_ESCAPE)
        {
            stopRunningApplication();
            return true;
        }
        return false;
    }
Works perfectly.
Done.
}

----------
19.04.2025
----------

{
Now let's look at this TO-DO item:
    Create an ASSERT() mechanism

Did some research on what are common ways of implementing an ASSERT() macro.
Created this new macro
    PK_ASSERT(CND, MSG, SND)
in
    PekanLogger.h
It takes in a condition, a message and a sender.
Message and sender have the exact same meaning as in PK_LOG_ERROR() and the other log macros.
Condition is a condition to be checked - if it's false only then the message should be shown,
and code should break on this line.
This should happen only in debug builds.
In non-debug builds the condition should just be executed as normal code.

To do this properly I added this new function in PekanLogger.h
    void _logAssertToConsole(const char* msg, const char* sender, const char* condition);
and implemented it in PekanLogger.cpp

That's about it. Not much to say.

Then I went through all places where PK_LOG_*() macros are used
and I changed some of them to PK_ASSERT().
Tested all demos. Tested how a failing assertion looks like.
Looks good. Done.
}

----------
21.04.2025
----------

{
Now let's look at this TO-DO item:
    Create a Window class

It's fairly straightforward. Mostly just refactored code from PekanEngine into this new class Window.
One thing worth mentioning is these 6 static functions in Window
    static void keyCallback(GLFWwindow* window, int key, int scancode, int action, int mods);
    static void mouseMovedCallback(GLFWwindow* window, double xPos, double yPos);
    static void mouseScrolledCallback(GLFWwindow* window, double xOffset, double yOffset);
    static void mouseButtonCallback(GLFWwindow* window, int button, int action, int mods);
    static void windowResizedCallback(GLFWwindow* window, int width, int height);
    static void windowClosedCallback(GLFWwindow* window);
They are registered as the 6 event callbacks in GLFW, using this function in Window
    void setEventCallbacks();
Exactly the same as it was in PekanEngine, but now class Window is not static,
so it kind of doesn't make sense that we register these static functions as event callbacks.
This is a temporary situation that we're in, because currently we support only 1 window and 1 application at a time.
In the future we must think about 1 application running across multiple windows
and then being able to have different event callbacks for each window.
For now we'll stick with having a single static set of event callbacks and having a single window.
That's just a future note.
That said, everything works as before, we just have window logic cleanly refactored into a Window class.
Done.
}

----------
25.04.2025
----------

{
I noticed a bug.
Setting these 2 member variables like that in a demo application's _init() function
    m_isFullScreen = true;
    m_shouldHideCursor = true;
doesn't work. Of course it doesn't because in PekanApplication::init() we are calling
    PekanEngine::init(this, m_isFullScreen, m_shouldHideCursor)
before calling demo application's _init().

Something is fundamentally wrong with Pekan's architecture there.
Trying to put it into words:
- A specific application should be able to configure window's properties at the init stage
- Creating a window should happen after that, because it needs to know the properties
- Loading OpenGL and initializing ImGui require a window (a GLFW context)
There are 2 options that I can think of
1. Separate window creation from engine initialization, so that PekanApplication can first initializa the engine,
   then call specific application's _init() function, and then create window by calling some function on PekanEngine.
2. Create a virtual function in PekanApplication that returns window's properties and can be overriden
   on specific applications to return the properties needed by the specific application.
   Then PekanEngine will call that function in its own init() function.
I will go with option 1 because I feel like it will be better for our future architecture.
Option 2 seems cleaner at this stage because we always have a single window,
but in the future I want Pekan to support multiple windows,
and also to work without a window at all, for example for console games or other types of mediums.

I did option 2.
More specifically, added a function
    static bool createWindow(WindowProperties properties);
in PekanEngine, and removed the 2 window-related parameters from PekanEngine::init(), now it's just this:
    static bool init(PekanApplication* application);
and the only thing it does currently is register the application.
Creating the window, loading OpenGL and initializing ImGui is done in createWindow().
Then specific applications should call createWindow(), if they want a window at all,
and they can configure the window by passing a WindowProperties object.
Additionally, now that engine initialization is separated from window creation,
it'd be good to have another member isWindowCreated, similar to isInitialized
    static bool isInitialized;
    static bool isWindowCreated;

By the way, I did set FPS to 60 in Demo03 and Demo02, because they are moving faster on my laptop display (higher refresh rate).
Should've done this together with the FPS commit earlier, but whatever, doing it now.

Bug is fixed now, architecture is better, and applications have cleaner and more flexible control over the window.
Done.
}

{
Now let's tackle this annoying TO-DO item
    Create Pekan enums corresponding to event-related enums in GLFW, like GLFW_KEY_W

Okay, it was not that annoying.
Created this new header file
    KeyEvent_Enums.h
containing this new enum class
    enum class KeyCode
that holds all key codes, with their numerical value matching that of GLFW key codes,
so that you can just cast a KeyCode enum into an int and use it with GLFW.

Similarly added this new header file
    MouseEvent_Enums.h
containing this new enum class
    enum class MouseButton
that holds just the values LeftButton and RightButton.
Later, we might need other mouse buttons, but for now we're good with just these 2.

Then we just include those headers in a couple of files, like KeyEvent.h and PekanEngine.h
and we make the key-related and mouse-button-related functions take in a KeyCode or a MouseButton instead of an int.

That's about it.
Everything works as before, but now we don't need to use GLFW enums in demo applications, we can use the new Pekan enums.
Done.
}

----------
02.05.2025
----------

{
Time to work on this TO-DO item
    Create an event queue so that events can be handled together at once, at a specific stage of the main loop.
Seems hard.

I considered a few different decisions along the way, argued with ChatGPT for a while :D
At the end what I did is fairly simple:

Created this new class in Event.h
    EventQueue
that is basically a wrapper over
    std::queue<std::unique_ptr<Event>>
a queue of base Event pointers.

Added this new member to PekanApplication
    EventQueue m_eventQueue;
Now each application has an event queue.
The idea is: Events that are not handled by any layer will be pushed to the event queue
and they can be processed all at once by a custom logic.
The custom logic of how to process the event queue will be this new virtual function in PekanApplication
    virtual void handleEventQueue()
Its default behavior is just to pop all events out of the queue.
A derived application can chose to override this function
and it will be called by PekanApplication's run() function, each frame.

That's about it. The rest is implementation details.

An architecture decision that I considered is if I should allow each layer to specify custom event queue handling logic,
so basically the virtual function
    virtual void handleEventQueue()
could be part of class Layer instead of class PekanApplication,
and then PekanApplication could call this function on each layer.
However, this leaves too much freedom to layers, because each layer can do whatever it wants with the event queue.
That's why I decided NOT to do it like that, and instead have a single event queue handling function inside of PekanApplication.
In the future it might make sense to do this per-layer thing, because we might want to allow certain layers
to handle certain events from the event queue and other layers to handle other events,
but for now I'm not too sure if it'd be needed, and it complicated things way too much.

Done.
}

----------
04.05.2025
----------

{
Next TO-DO item that I will implement is this
    Create a delta-time mechanism for FPS-independent movement

As an example I want the cube in Demo02 to rotate at the same speed no matter the FPS.

Okay, that was pretty easy.
Added this new class
    DeltaTimer
in 2 new files
    DeltaTimer.h
    DeltaTimer.cpp
under this new directory
    Time
in PekanCore, where I also put
    FpsLimiter.h
    FpsLimiter.cpp

The new class DeltaTimer is quite simple.
It has just 1 function
    double getDeltaTime();
which returns the "delta time", meaning the time that has passed since this function was last called.
If the function is called for the first time it will just return 0.0.
Imlpementation is straightforward.

Then how do we use this DeltaTimer class?
Well, we add this new member variable in PekanApplication
    DeltaTimer m_deltaTimer;
and then just use it in the run() function to get the delta time
    const double deltaTime = m_deltaTimer.getDeltaTime();
inside the main loop just before calling update() on all layers.
This deltaTime variable now contains the time passed since last frame.
We can pass this deltaTime to the update() function of all layers.
So we just add it as an extra parameter to Layer::update()
    virtual void update(double deltaTime) {}
Now each layer can access this deltaTime parameter in their update() function
and can use it to multiply their movement speeds, to achieve FPS-independent movement.

In Demo02 that would look like:
    m_rotation += float(60.0 * dt);
Instead of adding a constant (it was 1.0) we can add a constant times dt.
Now whatever FPS we use for Demo02, the cube will move with the same speed.

Done.
}

{
Next is this TO-DO item
    Create a way for derived applications to set up layer stack without directly touching the member variable m_layerStack...

Just added this output parameter
    LayerStack& layerStack
to the _init() function in PekanApplication
    virtual bool _init(LayerStack& layerStack) = 0;
Now derived applications can touch the layer stack only through this variable, only in this function.
Made the member variable
    m_layerStack
be private, together with all other member variables in PekanApplication.
Previously
    m_fps
needed to be protected because derived applications used to set m_fps directly inside of _init()
but now we have setFPS() for that, so m_fps doesn't need to be protected anymore, it should be private.

Done.
}

{
We have one final TO-DO item
    Use PekanEngine's event polling on these 2 lines in PekanApplication.cpp
        if (glfwGetKey(window, GLFW_KEY_ESCAPE) == GLFW_PRESS)
        glfwGetFramebufferSize(window, &windowWidth, &windowHeight);

This is actually already done.
First line doesn't exist anymore because we support custom closing logic and not always closing with escape key.
Second line has been changed to use Pekan's event polling
    const glm::ivec2 frameBufferSize = window.getFrameBufferSize();

Done.
}

{
All TO-DO items are done now.
We have 4 more features to implement, and 1 feature (layering) to test and maybe finish.

Let's start implementing
    RenderObject wrapper

----------
15.05.2025
----------

While implementing the RenderObject wrapper I needed to use PK_ASSERT a lot,
and I wanted to use it without a message or a sender, just to quickly check some condition.
Currently the PK_ASSERT macro requires 3 parameters - condition, message, sender.
Let's create a lighter version of PK_ASSERT, call it
    PK_ASSERT_QUICK
It's the same but with the condition only.

Okay, done implementing RenderObject wrapper. It's now under
    src/PekanRenderer/RenderObject.h
    src/PekanRenderer/RenderObject.cpp
I mostly copied it from Demo03, and changed all demos to use it.
One thing worth mentioning:
I added 2 overloads of the create() function, one without index data, and one without vertex data and index data.
Both of these overloads still create the vertex buffer and the index buffer but they create them empty.
Later client can fill vertex data and/or index data using the setVertexData() and setIndexData() functions.

All demos work as before. RenderObject's API looks good.
Done.
}

{
While we're at it let's do this new TO-DO item
    In RenderObject's setVertexData() and setIndexData() functions do something so that client doesn't have to provide BufferDataUsage each time.
    It should be optional.
    If they don't provide a BufferDataUsage then the BufferDataUsage passed in the beggining to the create() function should be used.

Okay, pretty easy.
I just added these 2 member variables to RenderObject:
    BufferDataUsage m_vertexDataUsage = BufferDataUsage::None;
    BufferDataUsage m_indexDataUsage = BufferDataUsage::None;
For their default values I had to add a new value to the BufferDataUsage enum - None.
Then in the create() functions if there is a vertexDataUsage parameter, then the m_vertexDataUsage member is set to that parameter.
That way we remember with what data usage was the render object created. Same for index data.
Then I added an overload of setVertexData() and an overload of setIndexData() that doesn't take in a data usage parameter.
In these 2 overloads we'll just use the 2 new members as data usage, if they are not none
(if they are none it means that the render object was not created with a data usage).
If they are none, we'll use a default data usage.
That's it.

Then I removed the data usage parameter from all calls of setVertexData() and setIndexData() where it was not needed.
All demos work as before.
Done.
}

{
Next feature is a big one:
    Textures.

Let's create a new demo
    Demo04
It will be very similar to Demo00 so let's begin with a copy of Demo00.
The only difference will be that we'll use a texture for the rectangle instead of a gradient color.

First of all, the way we'll read in image files to actual data in C++ is using this library
    stb
More specifically
    stb_image
It's a single-file public domain library. You can get it from here
    https://github.com/nothings/stb
We just need this single header file:
    stb_image.h
and we'll put it under
    dep/stb/
In order for it to work we also need a source file containing these 2 lines
    #define STB_IMAGE_IMPLEMENTATION
    #include <stb/stb_image.h>
Let's create a source file
    stb.cpp
under
    src/PekanCore/Utils
and paste those 2 lines there.
That's it, now we should be able to include <stb_image.h> and use functions from it.

As already said, we will use stb to load image files,
so let's create these 2 new files
    FileUtils.h
    FileUtils.cpp
under
    src/PekanCore/Utils
and write a single function
    const unsigned char* readImageFile(const char* filepath, int& width, int& height, int& numChannels);
that reads in an image from file and returns raw pixel data.
This function is basically a wrapper over
    stbi_load()
so that users of PekanCore can call this Pekan function instead of directly using stb.
It also flips the pixels by first calling
    stbi_set_flip_vertically_on_load(true);

It would be good to also have an Image class inside of PekanRenderer,
that keeps track of the pixel data, width, height, numChannels and other properties that an image might have.
So create a new class Image in 2 files
    Image.h
    Image.cpp
in PekanRenderer. We will need these members:
    const unsigned char* m_data = nullptr;
    int m_width = -1;
    int m_height = -1;
    int m_numChannels = -1;
and getters for each one of them. Then we'll also need a load function
    bool load(const char* filepath);
and for convenience we might also have a constructor for directly loading the image upon creation of an Image instance
    Image(const char* filepath) { load(filepath); }

Added a test image of the Teenage Mutant Ninja Turtles series from 2003 :D
    src/Demo04/resources/tmnt.png
Tried to load it using the Image class.
Seems to work.

Okay, we have images handled.
Now the hard part - implementing the actual textures.
We will create a new class
    Texture
in files
    Texture.h
    Texture.cpp
in
    PekanRenderer
that will be a basic wrapper over an OpenGL texture object.
It will, of course, derive from RenderComponent.
The main thing happening in this Texture class will be assigning an image to the texture object
    void setImage(const Image& image);
We will also have a create() overload that directly does this upon creation of the texture object
    void create(const Image& image);
like that:
    void Texture::create(const Image& image)
    {
        RenderComponent::create(false);
        setImage(image);
    }
Remember that we also have the default create() function coming from RenderComponent that just creates an empty texture object.
Now let's look at the implementation of setImage().
The main thing happening is that we assign the given image to the texture object with this OpenGL function
    glTexImage2D(...)
It requires a bunch of parameters. Some of them are easy to figure out, like the width and height of the image,
we already have those inside of the Image object itself. But some of them are harder to figure out, like the format and internal format.
They depend on the number of channels of the image, and we cannot directly pass the number of channels,
we need to pass GL_RGBA as the format if the number of channels is 4 for example, or we need to pass GL_RGB as the format if the number of channels is 3, etc.
For that we'll add a new static function inside of class Texture
    static void getFormat(const Image& image, unsigned& format, unsigned& internalFormat);
that determines the format and internal format that a texture must have to support the image.
Specifically we need the OpenGL enum values for the format and internal format, and that's exactly what the function fills in to the output parameters
    unsigned& format, unsigned& internalFormat
So that was all about the glTexImage2D() call.
Before it we need to configure a few other things about the texture.
We need to configure the minify and magnify function, and how the texture will wrap.
For now I will configure them with some hardcoded OpenGL values that seem reasonable as defaults.
Later we might need to provide user with control over these values, to allow them to configure them as they wish.
One final thing worth mentioning is the functions
    void bind()
    void unbind()
Textures are special in this regard, we don't just bind a texture,
we bind a texture to a specific texture slot (texture unit).
So we'll add these 2 overloads
    void bind(unsigned slot) const;
    void unbind(unsigned slot) const;
If I could I would remove the parameterless versions of bind() and unbind() because they don't make much sense,
but they are required from the base class RenderComponent. Inside of it bind() and unbind() are pure virtual so we need to implement them.
We will implement them to bind/unbind the texture to the currently active texture slot,
and we'll add a new function in Texture
    static void activateSlot(unsigned slot);
that activates a specific slot.
So now if users of class Texture want to bind a texture object to a specific slot, say 8, they can either do
    texObj.bind(8);
or
    Texture::activateSlot(8);
    texObj.bind();
First one is safer. Would recommend using it.
That's it. That's the Texture class.

Now let's see how we'll use the Texture class.
If we have a Texture object with a loaded image and we bind it to let's say slot 8 how can we actually use that texture?
Well, we need to use texture slot 8 inside of our fragment shader.
The usual workflow is that we have a uniform
    uniform sampler2D tex0;
inside of the fragment shader.
This uniform is supposed to be set from the CPU side to be equal to the desired slot, in this case 8,
so we would do this
    m_shader.setUniform1i("tex0", 8);
Then inside the shader we can use this tex0 together with the texture() function and a texture coordinate like that:
    texture(tex0, vTexCoord);
where vTexCoord is a vec2 containing the coordinates of the point of the texture that we need to sample.

To make all of this more convenient we'll integrate the Texture class inside of class RenderObject.
Let's add a member
    Texture m_texture;
This member will be created and destroyed the same way as other members in the create() and destroy() functions.
To actually set an image to the texture we'll add this new function
    void setTextureImage
    (
        const Image& image,
        const char* uniformName,
        unsigned slot
    );
that assigns the image to the texture like that
    m_texture.setImage(image);
but what it also does is set the uniform inside of the shader to be equal to the slot where the texture will be bound
    m_shader.setUniform1i(uniformName, slot);
How do we make sure that this same slot is the slot where the texture will be bound?
Well, we'll add this new member as well, to RenderObject
    unsigned m_textureSlot = 0xffffffff;
where we'll remember the slot where the texture is supposed to be bound.
So inside of setTextureImage() we will also set
    m_textureSlot = slot;
Then when binding the whole RenderObject we will bind the texture to this same slot, like that
    if (m_textureSlot != 0xffffffff)
    {
        m_texture.bind(m_textureSlot);
    }
This, of course, happens only if an image has been assigned and a slot exists.
Otherwise the texture is empty and won't be used.

So now how do we use a RenderObject with a texture?
We need one final thing, and that's to specify UV coordinates (texture coordinates) of each vertex.
So we'll change the color vertex attribute to be a "texCoord" vertexAttribute.
That's a vertex attribute of type vec2 and it specifies what texture coordinates each vertex should have.
    (The last 2 numbers of each row are the UV coordinates)
    const float vertices[] =
    {
        0.8f,  0.8f, 1.0f, 1.0f, // top right
        0.8f, -0.8f, 1.0f, 0.0f, // bottom right
        -0.8f, -0.8f, 0.0f, 0.0f, // bottom left
        -0.8f,  0.8f, 0.0f, 1.0f  // top left
    };
    ...
    { { ShaderDataType::Float2, "position" }, { ShaderDataType::Float2, "texCoord" } },
Then these texture coordinates will be interpolated for every pixel in between the vertices, so for every pixel inside a triangle,
and we'll receive this varying variable
    in vec2 vTexCoord;
inside of the fragment shader. It will contain the texture coordinates of the current pixel, telling it to which point of the texture it corresponds.
Then we can sample the texture like that
    FragColor = texture(tex0, vTexCoord);
and we have our fragment color.

That's it.
Testing all of that with the TMNT image.
Seems to work. Textures are ready.
Done.
}

----------
17.05.2025
----------

{
Next feature is also a big one
    Wrappers for 2D shapes

I'll do them one by one, starting from triangle.

Before starting let's restructure the files in PekanRenderer a bit, because currently they are all in one place, there are no subdirectories.
Let's create a new directory inside PekanRenderer
    RenderComponents
and inside of it put all the files containing classes that derive from RenderComponent, together with the RenderComponent class itself.
Done.

Let's start with the triangle wrapper now.
Create 2 new files
    TriangleShape.h
    TriangleShape.cpp
under a new directory
    2D/Shapes

Later we might want to have a base class Shape and make TriangleShape derive from it,
but for now let's just implement class TriangleShape basing it on RenderObject.
The way we'll base it on RenderObject will NOT be through inheritance, instead we'll just have a member variable
    RenderObject m_renderObject;

For creating a TriangleShape we will require the 3 vertices obviously.
It would also be good to require a bool parameter called "dynamic" that tells us if we should create the vertex buffer
with dynamic data usage or static data usage.
So the create() function of TriangleShape will look like
    void create
    (
        glm::vec2 vertexA, glm::vec2 vertexB, glm::vec2 vertexC,
        bool dynamic = true
    );
The implementation is straightforward. We just create an array from the 3 vertex positions,
and we call m_renderObject.create() with it, passing the needed parameters.

What about the shader? What shader are we going to pass?
We might give freedom for user to pass their own shader, but for now we'll not do that.
Instead we will have an internal shader.
More specifically, we'll have a 2D vertex shader that takes in 2D vertex positions and does nothing
    src\PekanRenderer\assets\shaders\2D_vertex_shader.glsl
and a "solid color" fragment shader that colors each pixel with a fixed color which is provded via a uniform called "uColor"
    assets\shaders\SolidColor_fragment_shader.glsl
These 2 shaders are not specific to TriangleShape, we will use them for all 2D shapes
when we want to NOT do anything to the vertices on GPU, and to color each pixel a solid color.

So far we had loaded our shaders only in demo applications and the filepaths to those shaders were relative to the demo's working directory.
We cannot do that now. The filepaths of these 2 new shaders are inside of Pekan's folder structure and are relative to Pekan's root,
which is obviously independent from demo's working directory. Demos can be run from anywhere.
What can we do about it?
We can create a macro through CMake that points to Pekan's root or in this case to PekanRenderer's root.
It's done like that:
    target_compile_definitions(PekanRenderer PRIVATE PEKAN_RENDERER_ROOT_DIR="${CMAKE_CURRENT_SOURCE_DIR}")
Now at the moment of generating projects, this macro
    PEKAN_RENDERER_ROOT_DIR
will be set to the specific path to the PekanRenderer directory, in my case
    C:\dev\Pekan\src\PekanRenderer
We can use that macro to get filepaths to the 2 shaders like that:
    #define VERTEX_SHADER_FILEPATH PEKAN_RENDERER_ROOT_DIR "/assets/shaders/TriangleShape_vertex_shader.glsl"
    #define FRAGMENT_SHADER_FILEPATH PEKAN_RENDERER_ROOT_DIR "/assets/shaders/TriangleShape_fragment_shader.glsl"
Now we can easily pass the contents of the 2 shaders to m_renderObject.create() like that:
    Utils::readFileToString(VERTEX_SHADER_FILEPATH).c_str(),
    Utils::readFileToString(FRAGMENT_SHADER_FILEPATH).c_str()

What else?
We need a standard destroy() function,
and we need a render() function that just binds the render object and issues a draw call of 3 vertices
    m_renderObject.bind();
    PekanRenderer::draw(3);

Finally, we need to set the color uniform "uColor" inside render object's shader
    m_renderObject.getShader().setUniform4fv("uColor", { 1.0f, 0.0f, 0.0f, 1.0f });
For now setting a solid red color. Next commit we'll have to provide users of TriangleShape with control over the color.

Let's test it in Demo04.
Just draw a small triangle somewhere on screen, together with the textured rectangle.
It works!

Now let's allow user to set a color, instead of just hardcoding red.
Add these functions to TriangleShape
    inline glm::vec4 getColor() const { return m_color; }
    void setColor(glm::vec4 color);
and this member
    glm::vec4 m_color;
and then in setColor() we'll obviously set m_color to the given color,
but we'll also set the "uColor" uniform inside the shader, but only if the shader is valid (created)
    m_color = color;
    if (m_renderObject.getShader().isValid())
    {
        m_renderObject.getShader().setUniform4fv("uColor", color);
    }
That's it.
Test it in Demo04 by animating the color.
It works!

Now let's allow the triangle to be moved.
We can easily add a setVertices() function that just sets 3 entirely new vertices.
This is fine and we'll do it, but let's also have a function setPosition() that sets the position of triangle's origin.
Vertex positions will be considered relative to that origin.
We can also have a move() function that adds a deltaX and deltaY to triangle's origin.
So I added these 2 functions
    void setPosition(glm::vec2 position);
    void move(glm::vec2 deltaPosition);
and these members
    glm::vec2 m_position = glm::vec2(0.0f, 0.0f);
    glm::vec2 m_vertices[3] = { glm::vec2(0.0f, 0.0f), glm::vec2(0.0f, 0.0f), glm::vec2(0.0f, 0.0f) };
and some getters for them.
It works!

That's the TriangleShape basically.
Done.
}

----------
19.05.2025
----------

{
Before moving on to the next shape class, let's create a base Shape class
by extracting all the shape-common logic from TriangleShape.

Did it.
Looks pretty clean now!
Class Shape contains the position, color and render object and it defines all common actions.
The responsibility of class TriangleShape is only to provide the logic around the 3 vertices specifically.

I also added functionality for setting each individual vertex after having created the TriangleShape.
Tested it in Demo04. Works pretty well.

Code looks solid!
Done.
}

----------
20.05.2025
----------

{
Now that we have a good base class Shape let's create the next 2D shape wrapper
    RectangleShape

Did it.
Mostly straightforward. One interesting thing that's worth mentioning
is that we had made class Shape support only RenderObjects without indices and rendering without indices.
So I had to add support for indices in Shape.
Added this member
    bool m_usingIndices = false;
which is a flag telling us if the shape is using indices.
Also added this overload of createRenderObject()
    void createRenderObject(const void* vertexData, const void* indexData, bool dynamic);
that takes in indices.
So now if the Shape is created with this overload then m_usingIndices will be true.
We care about this flag when we want to render the Shape, so inside of the render() function we can do that
    if (m_usingIndices)
    {
        PekanRenderer::drawIndexed((getNumberOfVertices() - 2) * 3);
    }
    else
    {
        PekanRenderer::draw(getNumberOfVertices());
    }
I also added this function for convenience
    inline int getIndexDataSize() const { return (getNumberOfVertices() - 2) * 3 * sizeof(unsigned); }
for calculating the (expected) size of the index data.

What else?
The RectangleShape is a bit different from TriangleShape in that it doesn't give control over the 4 different vertices.
Instead a rectangle has a width and height and this is what users can provide.
The position coming from Shape is used as the position of the bottom left corner of the rectangle.
So if you position a rectangle on (X, Y) that's going to be the position of its bottom left corner.
So wherever you place a rectangle you are placing its bottom left corner.
Everything else is pretty standard.

Tested in Demo04. Works pretty well.
Done.
}

{
Next 2D shape wrapper
    CircleShape

Circles are a bit more interesting, but also a bit simpler.
They only have a radius so we'll need this member
    float m_radius = 0.0f;
plus getters and setters for it
    void setRadius(float radius);
    inline float getRadius() const { return m_radius; }
The create() function will take in a radius
    void create
    (
        float radius,
        bool dynamic = true
    );
How is it going to create the circle? What are the vertices of a circle?
Well, the standard way to render a circle is approximating it with a regular N-gon.
In other words dividing the circle's circumference into N equal parts,
and forming N triangles with the center, giving you a triangle fan.
For that to work we will have to issue a draw call with
    DrawMode::TriangleFan
instead of the default
    DrawMode::Triangles
Since the code that makes the draw call is inside of the base class Shape - inside of the render() function,
we need some way for derived classes to specify their draw mode.
So let's add this virtual function in class Shape
    virtual DrawMode getDrawMode() const { return DrawMode::Triangles; }
that returns the draw mode that needs to be used for rendering.
By default shapes will be rendered with DrawMode::Triangles
unless they override this function to return something else.
In the case of CircleShape we want it to be that:
    virtual DrawMode getDrawMode() const { return DrawMode::TriangleFan; }

Alright, now how do we generate the vertices of a circle?
Well, it depends on the number of segments, and it's good to make this number be configurable.
Add this member to class CircleShape
    int m_segmentsCount = 0;
together with a getter and a setter
    void setSegmentsCount(int segmentsCount);
    inline int getSegmentsCount() const { return m_segmentsCount; }
Then in the create() function we'll set this member m_segmentsCount equal to some default number of segments
    static const int DEFAULT_SEGMENTS_COUNT = 42;
    ...
    m_segmentsCount = DEFAULT_SEGMENTS_COUNT;
Now, generating the vertices obviously depends on the number of segments,
so we will have a different number of vertices based on the current number of segments.
This means we can't no longer have a static array of a constant number of elements, we need a vector
    std::vector<glm::vec2> m_vertices;
Then let's create a function
    void generateVertices();
that generates (or regenerates) circle's vertices based on the current number of segments.
The first vertex will be the center
    m_vertices.clear();
    m_vertices.push_back({ 0.0f, 0.0f });
Then we need m_segmentsCount + 1 more vertices placed evenly around the circle.
Why m_segmentsCount + 1 ?
Well, because the first and last vertex need to be at the same position to "close the loop".
The way the GPU renders a triangle fan is it draws a triangle from vertices 0, 1, 2, then 0, 2, 3,
then 0, 3, 4, ... , 0, N-3, N-2, then 0, N-2, N-1, where N is the number of vertices in the vertex buffer.
In our case vertex 0 is the center, then we want vertex 1 to be at
    cos(0), sin(0)
and vertex 2 to be at
    cos(2 * pi / m_segmentsCount)
    sin(2 * pi / m_segmentsCount)
and vertex 3 to be at
    cos(2 * 2 * pi / m_segmentsCount)
    sin(2 * 2 * pi / m_segmentsCount)
and vertex 4 to be at
    cos(3 * 2 * pi / m_segmentsCount)
    sin(3 * 2 * pi / m_segmentsCount)
etc.
The last vertex needs to be the same as the first one
    cos(0) = cos(m_segmentsCount * 2 * pi / m_segmentsCount)
    sin(0) = sin(m_segmentsCount * 2 * pi / m_segmentsCount)
so that the final triangle that connects the last point to the first point is also drawn.
(Otherwise the circle will be drawn as a pie with a missing piece)
So that's how we generate the vertices around the circle
    for (int i = 0; i <= m_segmentsCount; i++)
    {
        const float angle = i * 2.0f * PI / m_segmentsCount;
        const float x = m_radius * cos(angle);
        const float y = m_radius * sin(angle);
        m_vertices.push_back({ x, y });
    }

This function
    generateVertices()
will have to be called also when setting a new number of vertices
    void CircleShape::setSegmentsCount(int segmentsCount)
    {
        m_segmentsCount = segmentsCount;
        generateVertices();
        updateRenderObject();
    }

That's about it.
Tested it in Demo04 with 2 circles,
one of them has number of segments changing with time,
and the other has position, radius and color changing with time.
Seems to work pretty well.
Done.
}

----------
22.05.2025
----------

{
A little optimization can be done for CircleShape.
Currently it keeps its vertices in a vector like that
    std::vector<glm::vec2> m_vertices;
which is okay, but it uses dynamic memory.
Not perfect for a large number of circles.
Imagine a game where 1 million circles have to be rendered,
and all of them have the same fixed number of segments that is not going to change.
Then it makes more sense to store those circles in static memory.
Of course this would remove the ability to change number of segments dynamically,
which is not great - there might be scenarios where you want to change the number of segment dynamically,
for example depending on the size of the circle, when moving the camera.
In conclusion, we need both options.
So I will add another class
    class CircleShapeStatic
which will have a static fixed number of segments that cannot be change during the lifetime of an object.
The only compile-time way to specify number of segments is through a template parameter,
so CircleShapeStatic will need to be a template class
    template <unsigned NSegments = 42>
    class CircleShapeStatic : public Shape
and then the vertices can be kept like that:
    glm::vec2 m_vertices[NSegments + 2];
This change from vector to a static array leads to changes to the implementation of some functions,
but it's pretty straightforward.
One annoying aspect of using a template class is that we cannot have a .cpp file with function definitions anymore.
We need to have the definitions inside of the header, or a cleaner solution is to have another header
    CircleShapeStatic_impl.h
containing the definitions of the functions, and then we can just include this new header at the end of the old one
    #include "CircleShapeStatic_impl.h"

That's about it.
Testing it in Demo04. Changed the second circle to be a CircleShapeStatic
    Pekan::Renderer::CircleShapeStatic<> m_circleStatic;
Works same as before.
Done.
}

----------
23.05.2025
----------

{
Let's take a look at this TO-DO item
    Think about how many and which ones of the create() overloads in RenderObject we need.

Yeah I guess it makes sense to have only 2 overloads of create().
One with vertex data and one without.
The index data should be provided through a set method, same as a texture.
So basically remove the first create() overload and change the client code wherever this overload was used
to instead use the next overload and then call setIndexData(...).
Done.
}
