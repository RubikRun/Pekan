----------
13.10.2025
----------

Before starting work on v0.3 features
let's first do all TO-DO items

{
First TO-DO item is:
    Create a mechanism in Core where client code can register a callback function
    to be called every N seconds automatically. Use it for Gleam House's updateFireColors() function, for example.

1. This mechanism will work on an application level so we need some API in class PekanApplication
for registering a callback function to be called repeatedly automatically by Pekan.
Let's call such callback a "recurring callback" and let's create a new public function in PekanApplication:
    void registerRecurringCallback(std::function<void()> callback, float interval);
2. Internally, to store a list of such recurring callbacks we'll create a new struct
    struct RecurringCallback
in 2 new files in Core
    Time/RecurringCallback.h
    Time/RecurringCallback.cpp
It will, of course, store the callback function and the time interval between calls:
    std::function<void()> callback;        
    float interval = 0.0f;
but it will also store the elapsed time since last call
    float elapsed = 0.0f;
3. Then in PekanApplication we can have a vector of such recurring callbacks:
    std::vector<RecurringCallback> m_recurringCallbacks;
and, of course, in registerRecurringCallback() we will create a new RecurringCallback instance
from the given parameters and push it into the m_recurringCallbacks list,
or more directly we will use emplace_back:
    m_recurringCallbacks.emplace_back(std::move(callback), interval);
4. In PekanApplication's main loop which is in the run() function we'll need to
update all registered recurring callbacks. Let's create a function in PekanApplication for that:
    void updateRecurringCallbacks(float deltaTime);
It needs to loop over all registered recurring callbacks
    for (RecurringCallback& recurringCallback : m_recurringCallbacks)
and increase the elapsed time of each one with current frame's delta time:
    recurringCallback.elapsed += deltaTime;
If a recurring callback's interval elapses we need to call the actual callback
and reset the elapsed time to 0:
    if (recurringCallback.elapsed >= recurringCallback.interval)
    {
        recurringCallback.callback();
        recurringCallback.elapsed = 0.0f;
    }
5. That's it.
Tested it in Demo07 by creating 2 new member functions in Demo07_Scene
    void changeBackgroundColor();
    void changeRectangleColor();
that change background's color and rectangle's color, just switching it between 2 hardcoded colors.
Then in Demo07_Scene we can register these 2 functions as recurring callbacks in m_application:
    m_application->registerRecurringCallback
    (
        [this]() { this->changeBackgroundColor(); },
        1.0f
    );
    m_application->registerRecurringCallback
    (
        [this]() { this->changeRectangleColor(); },
        0.4f
    );
It works!

Done.
}

----------
15.10.2025
----------

{
Next TO-DO item is:
    Create a getRandomColor() overload in PekanUtils.h/cpp that takes in an RGB range where R, G and B's min/max can be different.

Now looking at
    PekanUtils.h
    PekanUtils.cpp
all functions there are for generating random stuff,
so let's rename these files to
    RandomizationUtils.h
    RandomizationUtils.cpp

Let's create 2 new functions for generating a random color:
    glm::vec4 getRandomColor(glm::vec3 rgbMin, glm::vec3 rgbMax, bool randomizeAlpha = false);
    glm::vec4 getRandomColor(glm::vec4 rgbaMin, glm::vec4 rgbaMax);
Done. Easy.
Also noticed the API is not very consistent across functions in this file,
so I changed all functions to take in min/max, NOT xRange, yRange, etc.
Nothing important about this change, it's just for consistency.

Done.
}

----------
17.10.2025
----------

{
Next TO-DO item is:
    Remove "static" from "static const" and "static constexpr" everywhere
    where used for global variables that are constant, defined in a single .cpp, and not supposed to be visible outside.
    It's redundant. Global constants have internal linkage by default.

Okay, done.
Went through the whole codebase, checked the usage of all "static const" occurrences
and removed "static" from the ones that are global variables.

Also, did an additional thing.
Changed "const" to "constexpr" everywhere where the data is known at compile time, for example:
    constexpr float COLOR_DULLNESS = 0.9f;
or
    constexpr char* const VERTEX_SHADER_FILEPATHS[] =
    {
        "resources/04_00_vertex_shader.glsl",
        "resources/04_01_vertex_shader.glsl",
        "resources/04_02_vertex_shader.glsl",
        "resources/04_03_vertex_shader.glsl"
    };
If data is NOT known at compile time then we must use "const" and NOT "constexpr", for example:
    const float cameraDist = m_guiWindow->getCameraDist();
or
    const int posX = int(INITIAL_POSITION_X * m_resolution.x);

While, we're at it, let's do another similar thing.
Let's remove "inline" from all functions defined inside a class.
It's not needed.
We only need "inline" if a function is defined outside a class but in the header file.
There is only one place that does this, and it's this function:
    inline std::ostream& operator<<(std::ostream& os, const Event& e)
    {
        return os << e.toString();
    }
in
    Event.h
so we'll keep this one as inline.
Removed all other instance of "inline".

Done.
}

----------
20.10.2025
----------

{
Next TO-DO item is
    Use
        inline static const
    everywhere to define static const member variables inside the class, instead of separately in the .cpp

Done.
}

----------
21.10.2025
----------

All TO-DO items are done now.

{
Time to start implementing v0.3 features.
I'll start with
    Entity Component System (ECS)

Decided to use a third party Entity Component System
because it's quite important that it's fast and reliable.
In the future we might implement our own ECS,
but for now let's integrate a third party one into Pekan
and see how exactly we want to use it.
After the usage of our ECS is clear we might reconsider and implement our own
or we might stick with the third party one, we'll see.

We will use
    EnTT
which is a free and open-source header-only ECS library for C++.
A good resource to get an idea of how to use EnTT and how to integrate it in a game engine
is, of course, The Cherno's Game Engine series.

First step would be to actually get EnTT and make it be a part of our project.
We'll get it as a git submodule. To do that, modify
    .gitmodules
appending this:
    [submodule "dep/entt"]
        path = dep/entt
        url = https://github.com/skypjack/entt.git
Then, to actually download the EnTT repository under
    dep/entt
we need to run
    git submodule update --init --recursive
(This, of course, will also have to be done on a freshly downloaded Pekan as well)

Now that we have the EnTT library under
    dep/entt
we need to set it up in CMake.
EnTT is a single-header library so we just need to be able to include this one header file:
    dep/entt/single_include/entt/entt.hpp
We can add this directory
    dep/entt/single_include
to Core's include directories in
    CMakeLists.txt
That way, we can include the header in our C++ files like this:
    #include <entt/entt.hpp>

To test if EnTT is setup correctly
let's include the header file in
    PekanApplication.cpp
and do a small test in PekanApplication::init()
We'll create an entt registry
    entt::registry registry;
Create 2 dummy structs that we'll use as components
    struct Position { float x, y; };
    struct Velocity { float vx, vy; };
Create an entity
    entt::entity e1 = registry.create();
and add the 2 components Position and Velocity to it with some values for x, y and vx, vy
    registry.emplace<Position>(e1, 1.0f, 2.0f);
    registry.emplace<Velocity>(e1, 0.1f, 0.2f);
Create another entity
    entt::entity e2 = registry.create();
and add just 1 of the components - Position - to it with some values for x, y
    registry.emplace<Position>(e2, 3.0f, 4.0f);
Then, we can get a "view" of all Position components in our registry, like this:
    registry.view<Position>()
and we can ask the size of this view
    const size_t posCount = registry.view<Position>().size();
which will give us the number of Position components in the registry: in this case 2
We can do the same for the Velocity components - get a "view" of them, and ask for its size:
    const size_t velCount = registry.view<Velocity>().size();
That's it.
Now we can debug and/or log the values of posCount and velCount
to make sure that they are 2 and 1, and indeed, they are.
It works!

We succesfully set up EnTT in Pekan!

Done.
}

----------
22.10.2025
----------

{
Let's continue with ECS now.
My idea for the next step is to implement a new class
    class Scene
that derives from class Layer
and has its own Entity Component System registry, which is this:
    entt::registry
Inside a scene client code will be able to create entities
and assign them different components.
Still not sure how and where we would implement the systems, but we'll see.

Let's start from somewhere.
Create an new class derived from class Layer
    class Scene : public Layer
in 2 new files in Core
    Scene.h
    Scene.cpp
We need just 2 things inside the class for now:
First, the constructor - class Scene needs to only be able to be constructed with an application pointer,
same way as the underlying Layer:
    Scene(PekanApplication* application) : Layer(application) {}
Second, we need to implement the getLayerName() function because it's pure virtual in class Layer
    virtual std::string getLayerName() const override { return "scene_layer"; }
Scene layers will be called
    "scene_layer"
by default. Client code can override this and provide another name.

Let's also create a new demo
as a playground where we can test the ECS while developing it.
Created
    Demo09
in a standard way, copied from Demo00
but removed everything from
    class Demo09_Scene
and made it derive from our new Scene class
    class Demo09_Scene : public Pekan::Scene
Only thing left in the class is the constructor:
    Demo09_Scene(Pekan::PekanApplication* application) : Pekan::Scene(application) {}
}

----------
23.10.2025
----------

{
Continuing with ECS.
The goal now is:
1. Change our Transformable2D class to be a component
2. Change our Sprite class to be a component
3. Create an entity with a Sprite component in Demo09

For 1. we'll need to separate Transformable2D into 2 new classes (or a struct and a class):
    struct TransformComponent2D
    class TransformSystem2D
into these 3 new files:
    TransformComponent2D.h
    TransformSystem2D.h
    TransformSystem2D.cpp
In simple terms we need TransformComponent2D to hold a transform's data
and TransformSystem2D to provide functionality for operating on that data.
It's good to keep components as minimal as possible,
so our TransformComponent2D will only have these 4 members:
    glm::vec2 position = { 0.0f, 0.0f };
    float rotation = 0.0f;
    glm::vec2 scale = { 1.0f, 1.0f };
    entt::entity parent = entt::null;
Let's not worry about optimization for now, and get rid of all "dirty flag" optimizations and caches.
Later we might bring them back but they will probably operate a bit differently in ECS.
(Created a TO-DO item for bringing them back)
Then, in TransformSystem2D we need to have functions that operate on entities that have a TransformComponent2D.
We'll keep those as simple as possible.
For now we only need getters and setters for position, rotation and scale,
and a getter for world matrix:
    static glm::vec2 getPosition(const entt::registry& registry, entt::entity entity);
    static float getRotation(const entt::registry& registry, entt::entity entity);
    static glm::vec2 getScale(const entt::registry& registry, entt::entity entity);
    static void setPosition(entt::registry& registry, entt::entity entity, glm::vec2 position);
    static void setRotation(entt::registry& registry, entt::entity entity, float rotation);
    static void setScale(entt::registry& registry, entt::entity entity, glm::vec2 scale);
    static glm::mat3 getWorldMatrix(const entt::registry& registry, entt::entity entity);
Just for completeness let's also add move(), rotate() and scale() as we had in Transformable2D:
    static void move(entt::registry& registry, entt::entity entity, glm::vec2 deltaPosition);
    static void rotate(entt::registry& registry, entt::entity entity, float deltaRotation);
    static void scale(entt::registry& registry, entt::entity entity, glm::vec2 deltaScale);

Okay, now we have a component and a system
that can be used by both our code and client code.
But to use them we need a registry.
Where is this registry going to live?
In the scene, of course.
Every scene will have its own ECS registry.
So let's add an entt::registry to our Scene class, as a private member:
    entt::registry m_registry;
together with protected getters (const and non-const):
    entt::registry& getRegistry() { return m_registry; }
    const entt::registry& getRegistry() const { return m_registry; }
Now scene classes that derive from Scene can access this registry
and use it together with our new TransformComponent2D and TransformSystem2D classes.
We'll need one more thing in class Scene:
(we don't strictly need it if we're being 100% minimal, but we'll add it for convenience)
We need protected functions for creating and destroying an entity:
    entt::entity createEntity();
    void destroyEntity(entt::entity entity);
Now derived scenes can easily create and destroy entities
and they can access the registry and use it together with components and systems provided by Pekan,
or with their own.

Let's do an example in Demo09.
We'll use a turkey texture for our sprite later on, so let's have an entity called
    entt::entity m_turkey;
in Demo09_Scene and let it have a default value of null
    entt::entity m_turkey = entt::null;
Then in Demo09_Scene's init() function we can create the turkey entity like this:
    m_turkey = createEntity();
and we can add a TransformComponent2D component to it like this:
    registry.emplace<TransformComponent2D>(m_turkey);
where on a previous line we get registry like this:
    entt::registry& registry = getRegistry();
If we want our turkey to be initialized with some initial position, not just at (0, 0), we can do this:
    registry.emplace<TransformComponent2D>(m_turkey, TURKEY_INITIAL_POSITION);
where TURKEY_INITIAL_POSITION is a global constexpr:
    constexpr glm::vec2 TURKEY_INITIAL_POSITION = glm::vec2(-0.5f, -0.2f);
Then in the update() function we can move the turkey slightly, like this:
    TransformSystem2D::move(registry, m_turkey, glm::vec2(0.02f, 0.01f));
Finally, to verify that everything works we can get turkey's world matrix:
    const glm::mat3 turkeyMatrix = TransformSystem2D::getWorldMatrix(registry, m_turkey);
and log it with PK_LOG_INFO so that we can see the world matrix every frame,
and we can see how it changes as turkey moves.
It works!

----------
24.10.2025
----------

{
    Before continuing with ECS let's remove this CMake option
        PEKAN_USE_1D_TEXTURE_FOR_2D_SHAPES_BATCH
    It will simplify things a lot. We might bring it back later on, or not (it was not very needed to begin with).
    We'll keep code as if the option is on.
    Done.
}

----------
25.10.2025
----------

For 2. we'll need to bypass RenderBatch2D and directly render our sprites.
Later we must think about bringing back RenderBatch2D and making it part of ECS
but for now we can't bother with that, we must first implement Sprite rendering
and then Shape rendering in the most straightforward way possible,
and only then bring back RenderBatch2D (or an alternative).

Let's implement a sprite component and a sprite system now.
We'll have 3 new files
    SpriteComponent.h
    SpriteSystem.h
    SpriteSystem.cpp
same as how we did with transform component and system.
First, we'll have a struct
    struct SpriteComponent
that contains only the data of a sprite.
A sprite needs width, height, a texture, and min/max of texture coordinates.
So the struct will consists of:
    float width = 0.0f;
    float height = 0.0f;
    Graphics::Texture2D_ConstPtr texture;
    glm::vec2 textureCoordinatesMin = { 0.0f, 0.0f };
    glm::vec2 textureCoordinatesMax = { 1.0f, 1.0f };
That's it. Simple as that.
Then we'll have a class
    class SpriteSystem
that will provide functionality over sprite components.
What functionality do we need?
Rendering.
That's all we need. We need to be able to render an entity with a sprite component.
    static void render(const entt::registry& registry, entt::entity entity);
The complicated part is what this function will do internally, but externally it's dead simple, just render().
So let's see how to implement this render function.
We said that we'd bypass RenderBatch2D for now and directly render sprites then and there.
So in this render function we will need to construct sprite's world vertices
taking into account the SpriteComponent, obviously, but also the TransformComponent2D.
Then once we have sprite's world vertices we'll need to create a render object with them,
provide an appropriate shader and index data,
and use SpriteComponent's texture.
That's the basic plan.
Implementing it is not that hard.
{
    Before proceeding to the implementation though let's think about
    what data structure we'll use for sprite's world vertices.
    Until now we used
        Vertex2D
    but this is a struct specifically targeted for batch rendering of sprites AND shapes together.
    We'll not be doing this for now, so let's have a new struct
        struct SpriteVertex
    in a new file
        SpriteVertex.h
    and let it contain only the data needed for a sprite vertex (no batch metadata, no shape data):
        glm::vec2 position = { -1.0f, -1.0f };
        glm::vec2 textureCoordinates = { -1.0f, -1.0f };
    That's it. That's our SpriteVertex that we'll use in SpriteSystem.
}
We first need to extract the SpriteComponent and TransformComponent2D from the given entity:
    const SpriteComponent& sprite = registry.get<SpriteComponent>(entity);
    const TransformComponent2D& transform = registry.get<TransformComponent2D>(entity);
Before that we can assert that entity exists and it has those 2 components:
    PK_ASSERT(registry.valid(entity), "Trying to render an entity that doesn't exist.", "Pekan");
    PK_ASSERT(registry.all_of<SpriteSystem>(entity), "Trying to render an entity that doesn't have a SpriteComponent component.", "Pekan");
    PK_ASSERT(registry.all_of<TransformComponent2D>(entity), "Trying to render an entity that doesn't have a TransformComponent2D component.", "Pekan");
Once we have entity's SpriteComponent and TransformComponent2D we will create a RenderObject out of them.
For that we'll have a helper function that we'll use like this:
    RenderObject renderObject;
    createRenderObjectForSprite(registry, sprite, transform, 0, renderObject);
The hardcoded 0 is the texture slot that we want the uniform inside the shader to be set to.
And on the next line we'll bind sprite's texture to this same slot 0
    sprite.texture->bind(0);
Finally, we need to render the render object
    renderObject.render();
That's the end of SpriteSystem::render()
Let's look at the implementation of
    createRenderObjectForSprite()
First we need to create world vertices out of sprite's components:
    SpriteVertex verticesWorld[4];
    getVerticesWorld(registry, sprite, transform, verticesWorld);
Again using a helper function for that:
    getVerticesWorld()
Then we create the render object from the world vertices in a pretty standard way:
    renderObject.create
    (
        verticesWorld,
        sizeof(SpriteVertex) * 4,
        {
            { ShaderDataType::Float2, "position" },
            { ShaderDataType::Float2, "textureCoordinates" }
        },
        BufferDataUsage::DynamicDraw,
        FileUtils::readTextFileToString(VERTEX_SHADER_FILEPATH).c_str(),
        FileUtils::readTextFileToString(FRAGMENT_SHADER_FILEPATH).c_str()
    );
We know that a sprite will always have 4 vertices so we can hardcode this
    sizeof(SpriteVertex) * 4
and we know the exact vertex layout
    {
        { ShaderDataType::Float2, "position" },
        { ShaderDataType::Float2, "textureCoordinates" }
    }
As for the 2 shaders they are these 2 new shaders:
    #define VERTEX_SHADER_FILEPATH PEKAN_RENDERER2D_ROOT_DIR "/Shaders/2D_Sprite_VertexShader.glsl"
    #define FRAGMENT_SHADER_FILEPATH PEKAN_RENDERER2D_ROOT_DIR "/Shaders/2D_Sprite_FragmentShader.glsl"
that I got from
    2D_Batch_VertexShader.glsl
    2D_Batch_FragmentShader.glsl
by removing batch metadata and shape data, and leaving only sprite rendering.
Once we have created the render object we need to set index data to it:
    static constexpr unsigned indices[6] = { 0, 1, 2, 0, 2, 3 };
    renderObject.setIndexData(indices, sizeof(unsigned) * 6);
That's easy because a sprite's index data is always the same - 0, 1, 2, 0, 2, 3 - just forming a rectangle out of 2 triangles.
And finally we need to set render object's shader's uniforms.
More specifically we need to set
    uniform mat4 uViewProjectionMatrix;
and
    uniform sampler2D uTexture;
To set the view projection matrix we'll use the currently active camera in Renderer2DSystem:
    Camera2D_ConstPtr camera = Renderer2DSystem::getCamera();
    setViewProjectionMatrixUniform(shader, camera);
using a helper function
    setViewProjectionMatrixUniform()
which is the same one from RenderBatch2D.cpp,
it gets camera's view projection matrix and sets uniform to it, unless camera is null then it sets default identity matrix.
To set the "uTexture" uniform we just set it to the given texture slot, easy as that:
    shader.setUniform1i("uTexture", textureSlot);
That's it.
Our SpriteSystem now supports rendering of entities that have both SpriteComponent and TransformComponent2D.

{
    Side note, until now we had this strict create()/destroy() or init()/exit() logic going on
    with mouse of our classes, which was very good for the more OOP design that we had,
    but now with ECS it doesn't make that much sense.
    Specifically, we don't want to manually call destroy() on things, we want it to be okay for them
    to just go out of scope and get destroyed automatically.
    So, what we need for now in this direction is to allow destructors to call destroy()
    instead of asserting that the object is not valid.
    Most of our classes in Graphics do this. It looks like:
        VertexBuffer::~VertexBuffer()
        {
            PK_ASSERT(!isValid(), "You forgot to destroy() a VertexBuffer instance.", "Pekan");
        }
    TL;DR we need to change destructors to do this instead:
        VertexBuffer::~VertexBuffer()
        {
            if (isValid())
            {
                destroy();
            }
        }
    Done.
}

Client code can now just call
    SpriteSystem::render()
for each entity that it wants to render in its scene's render() function,
but it will definitely be better that this rendering happens automatically.
What I mean is that all sprite entities that exist in client's scene
must get rendered automatically (unless specified otherwise, we might make an option like this later)
How to do that?
We can have another render() function in SpriteSystem that renders a whole ECS registry
    static void render(const entt::registry& registry);
That's a perfect use case to utilize the power of ECS.
We can very easily get a view of all entities in the registry that have SpriteComponent and TransformComponent2D:
    const auto view = registry.view<SpriteComponent, TransformComponent2D>();
and then just render each one of them with the already implemented render() function:
    for (entt::entity entity : view)
    {
        render(registry, entity);
    }
Now that we have this, client code can just do this in their render function:
    SpriteSystem::render(getRegistry());
and render all of their sprite entities.

We can do slightly better.
Let's have a new class
    class Scene2D
in 2 new files
    Scene2D.h
    Scene2D.cpp
in module Renderer2D.
This new Scene2D class will inherit from Scene, of course:
    class Scene2D : public Scene
and it will override the render function
    void render() const override;
with automatically calling SpriteSystem::render() on the scene's registry:
    const entt::registry& registry = getRegistry();
    SpriteSystem::render(registry);
We can also make it always clear the window before that:
    RenderCommands::clear();
(it's not technically correct to clear in every scene, because we might have more than one scene)
(we only need this temporarily until TO-DO item 0071 is done)
And to allow some flexibility on the render logic we'll provide a virtual function
    virtual void _render() const {}
that client code can choose to override with custom rendering logic that will be done ON TOP OF Scene2D's render logic,
so we need to call _render() in render() after doing the other stuff
    _render();
That's it.
Now we can make Demo09_Scene derive from Scene2D instead of Scene
and remove the render() function, and we have sprite entities being rendered by default.

Also did 3. didn't even notice, but yeah, we've got a working example in Demo09.

Done.
}

----------
27.10.2025
----------

{
Next step for integrating ECS in Pekan is to integrate shapes.
Until now we had a base class
    class Shape
and children classes RectangleShape, CircleShape, etc. for each specific shape type.
We can't do this anymore.
We have 2 options:
Option A:
    We can have 1 component and 1 system per shape type, for example:
        for rectangles -> RectangleShapeComponent, RectangleShapeSystem
        for triangles -> TriangleShapeComponent, TriangleShapeSystem
        for circles -> CircleShapeComponent, CircleShapeSystem
        etc.
    Then each system renders all entities of a specific shape type
Option B:
    We can have 1 component and 1 system for all shape types:
        ShapeComponent
        ShapeSystem
    with a "shape type" field in ShapeComponent.
    Then ShapeSystem will do the rendering based on that "shape type" field.

Option B is better for batching all shapes together no matter their type,
but in Option B each ShapeComponent will contain some redundant data.
For example if we have a ShapeComponent with "shape type" being "rectangle"
then the "width" and "height" fields of ShapeComponent will be used,
but for example the "radius" field will NOT be used.

Option A is more straightforward and cleaner, I'd say.
It does require us to batch different shape types separately, but that's fine,
we have only a few shape types anyway, and we don't plan on having a big number of shape types in the future
(at most 10 i can imagine).
We can afford rendering a few batches of shapes instead of just one batch of shapes.

We'll go with option A.

Let's start with rectangles, because they are most similar to sprites.
Okay, did rectangles.
Decided it's time to separate geometry from materials,
so I created
1.
    struct RectangleGeometryComponent
    class RectangleGeometrySystem
that are responsible for a rectangle's geometry:
    - front end: width, height
    - back end: API for generating vertex positions
2.
    struct SolidColorMaterialComponent
that holds material data, in this case:
    - fron end: color
    - back end: API for generating vertex colors
Then I also created
    class Renderer2DSystem_ECS
for doing the actual rendering of rectangles with solid color materials
and I did all render code there.
Not sure if that will be the final look of things,
so I'll not dig into it too much.
Let's continue with other shape types and we'll see how everything will come together.

----------
03.11.2025
----------

Finished integrating shapes in ECS.
Sum up:

For each shape type we have a *Component struct:
    struct RectangleGeometryComponent
    struct LineGeometryComponent
    struct CircleGeometryComponent
    struct TriangleGeometryComponent
    struct PolygonGeometryComponent
Each of them contains the front-end data of shape's geoemtry,
which are the parameters that we want to expose to the end user,
and nothing more.

For each shape type we have *System class:
    class RectangleGeometrySystem
    class LineGeometrySystem
    class CircleGeometrySystem
    class TriangleGeometrySystem
    class PolygonGeometrySystem
Each of them provide an API for getting shape's vertex positions
    getVertexPositions()
Some of them (CircleGeometrySystem and PolygonGeometrySystem)
have this API get vertex positions AND indices as well:
    getVertexPositionsAndIndices()
For the rest (RectangleGeometrySystem, LineGeometrySystem, TriangleGeometrySystem)
it's clear what the indices are because they do NOT change between specific instances of the shape type.
However for CircleGeometrySystem and PolygonGeometrySystem the indices DO change between instances.
(
    For example a circle with 32 segments and a circle with 64 segments
    will have different indices,
    or a polygon with 8 vertices and a polygon with 11 vertices will have different indices.
    Even polygons with the same number of vertices can have different indices because of triangulation.
)
So these 2 shape types generate vertex positions together with indices.
It makes sense to generate those at once, and not separate the API into 2 APIs
because indices are very much linked with what the vertices are.
Together they form the shape's "geometry".

What else?
The actual rendering is separated from the generating of geometry.
It happens in
    class Renderer2D_ECS
It has a single function
    static void render(const entt::registry& registry);
that just renders all entities that can be rendered.
It renders all shape types and all sprites.

A thing worth mentioning is how the geometry systems get vertex positions
into Renderer2D_ECS and how the SolidColorMaterialSystem gets vertex colors
into Renderer2D_ECS.
It's not as straightforward as just returning an array of vertex positions
or an array of vertex colors, unfortunatelly.
The reason is that Renderer2D_ECS needs to have a single array of vertices,
where each vertex has a position and a color,
as opposed to having 2 arrays - one of positions and one of colors.
So Renderer2D_ECS is responsible for creating an array of vertices
    struct VertexOfShapeWithSolidColorMaterial
    {
        glm::vec2 position = { 0.0f, 0.0f };
        glm::vec4 color = { 1.0f, 1.0f, 1.0f, 1.0f };
    };
    ...
    std::vector<VertexOfShapeWithSolidColorMaterial> vertices(verticesCount);
and then geometry systems and SolidColorMaterialSystem are responsible
for filling the positions or colors into this array at the correct offsets.
For example the API
    getVertexPositions()
of
    RectangleGeometrySystem
takes in these 3 parameters
    void* vertices,
    int vertexSize,
    int positionAttributeOffset
First one is a pointer to the actual array of vertices where vertex positions need to be filled.
Second and third one tell it how exactly to fill them.
In this case the API needs to put
    - first vertex position in bytes 0-7    (8 bytes is the size of glm::vec2)
    - then skip 16 bytes                    (16 bytes is the size of the color attribute which is glm::vec4)
    - second vertex position in bytes 24-31
    - then skip 16 bytes
    - third vertex position in bytes 48-55
    ...
Same story with the API of SolidColorMaterialSystem.

Another thing to note is that I created this helper class
    ShapeGeometryUtils
with utility functions for generating geometry of shapes.
It has some common functions mostly for applying world matrix to local vertex positions.

That's about it.
All shape types are rendered correctly now in ECS.
Demo09_Scene is testing each one of them and they seem to work fine.
There are no optimizations, of course, I removed all of them to make this transition to ECS easier.
We'll have to introduce them back in, one by one with the time.

Done.
}

----------
08.11.2025
----------

{
Integrated cameras in ECS.
Here's a sum up:

Created a struct
    struct CameraComponent2D
in 2 new files
    CameraComponent2D.h
    CameraComponent2D.cpp
containing the data of a camera:
    glm::vec2 size = { 0.0f, 0.0f };
    glm::vec2 position = { 0.0f, 0.0f };
    float zoomLevel = 1.0f;
    bool isPrimary = true;
    bool isControllable = true;
Worth noting are the last 2 members - isPrimary and isControllable.
We did NOT have those in Camera2D.
They are flags for marking a camera component as "the primary camera"
or "the controllable camera".
The primary camera will be the one used for rendering,
and the controllabe camera will be the one that user controls with the mouse.
CameraComponent also contains some getter/setter type of functions
    getViewProjectionMatrix()
or
    setWidth()
    setHeight()
for setting the width/height of a camera and having the option
to lock the height/width to it so that it matches window's aspect ratio.
And so on.
Basically moved most of the functions from Camera2D to CameraComponent2D,
or more specifically the ones that have to do with data only.
Functionality that has to do with all cameras in the scene will be in the system, not the component.

Then, created a class
    class CameraSystem2D
in 2 new files
    CameraSystem2D.h
    CameraSystem2D.cpp
We need only 2 APIs there - one for getting the primary camera from a scene's registry
and one for getting the controllable camera from a scene's registry:
    static const CameraComponent2D& getPrimaryCamera(const entt::registry& registry);
    static const CameraComponent2D* getControllableCamera(const entt::registry& registry);
A thing worth mentioning is that getPrimaryCamera() will ALWAYS return a camera component,
even if there is no primary camera in the scene or even if there is no camera at all in the scene.
It will return a default camera, which we have as a static global variable in the .cpp file:
    static constexpr CameraComponent2D g_defaultCamera = getDefaultCamera();
Did it like that because the primary camera is used for rendering and we always want to render something.
As opposed to that, getControllableCamera() might return a null pointer
if there is no controllable camera in the scene
and that's fine because then user will just NOT control any camera with the mouse.

Probably the most interesting part is the way I did camera controller.
Created a class
    class CameraController2D
in 2 new files
    CameraController2D.h
    CameraController2D.cpp
It's a class that derives from EventListener:
    class CameraController2D
        : public EventListener
because it will be registered as an event listener in PekanApplication
The way it works is that every
    Scene2D
instance has its own CameraController2D instance
and CameraController2D has an init() function
that is called from Scene2D's init() function.
That's how we make sure that CameraController2D's init() function
will be called at the right time - when the application is initalized,
and only if client code is using a 2D scene at all.
Then, in CameraController2D's init() function we can register the CameraController2D instance
as an event listener in the current PekanApplication:
    application->registerEventListener(shared_from_this());
Yes, I had to do the weird shenanigans with
    std::enable_shared_from_this
CameraController2D derives from this, so that we can pass
    shared_from_this()
to
    registerEventListener()
because otherwise the raw "this" pointer wouldn't work.
I really don't love this approach, but what can you do,
we may think of some alternative of smart pointers in the future,
not sure yet. For now it's ok like that.
What more?
Upon initialization, in the init() function CameraComponent2D also saves a pointer to the Scene2D
in this member variable:
    Scene2D* m_scene = nullptr;
so that it can use this scene to get the controllable camera from it using CameraSystem2D:
    CameraSystem2D::getControllableCamera(m_scene->getRegistry());
Everything else is pretty much the logic from the old camera controller, the one in
    PekanTools
Now CameraController2D works out of the box in a Scene2D.
If there is an entity with a CameraComponent2D with isControllable = true
then the camera controller will work for this camera.
Tested it in Demo09. It works.

All other aspects of the camer also work normally in Demo09.
That's it, we have cameras in ECS!
Done.
}

----------
09.11.2025
----------

{
Decided to see if post-processing shaders will work normally with ECS.

Tried doing the same post-processing logic from Demo06 in Demo09.
It worked almost out of the box.
Only thing I had to do was to put
    PostProcessor::beginFrame()
and
    PostProcessor::endFrame()
in Scene2D's render() function
since client code in Demo09 does NOT have a render() function anymore.
Rendering is handled by the base Scene2D class,
client code is only responsible for creating renderable entities in ECS
and they are rendered automatically by Scene2D's render() function.

The obvious problem here is that this will fail when client code doesn't use a post-processing shader.
If client code doesn't call
    PostProcessor::init()
passing a specific post-porcessing shader then the calls to beginFrame() and endFrame() will fail.

Let's restructure PostProcessor a little bit.
We'd want this new API in PostProcessor instead of the init() API:
    static void setPostProcessingShader(const char* postProcessingShaderFilepath);
So now there is a single thing that client code has to do to use a post-processing shader - just set it.
First time it's set the PostProcessor will be internally initialized.
For that, I changed the init() function to be a global static function inside the .cpp
and it's automatically called the first time setPostProcessingShader() is called
    if (!g_isInitialized)
    {
        if (!init())
            ...
    }
Then, we also need to change beginFrame() and endFrame() to do nothing
if PostProcessor is not initialized or if there is no post-porcessing shader set
    if (!g_isInitialized || !g_hasSetPostProcessingShader)
    {
        return;
    }
Now it's perfectly safe for Scene2D's render() function to always call beginFrame() and endFrame()
no matter if user is using a post-processing shader - this logic will be handled internally in PostProcessor.

NOTE: This means that scenes that do NOT use ECS will have to manually call beginFrame() and endFrame()
in their render() functions as they did until now.

Okay, it works now.
Considering PostProcessor "integrated" in ECS now.
It's not really "integrated" because it's not part of ECS,
but we made Scene2D and PostProcessor handle everything except the actual user choice.

Done.
}

----------
12.11.2025
----------

{
Time to integrate line primitives in ECS now.
We already have LineGeometryComponent and LineGeometrySystem
but these are for rendering a line geometry - basically a thin rectangle.
We want to also have support for line primitives - directly rendering a line,
no thickness, just 2 vertices, basically what we had until now in class Line,
as opposed to class LineShape which was the rectangular line.

Okay, that was easy. Pretty straightforward.
Created 3 new files
    LineComponent.h
    LineSystem.h
    LineSystem.cpp
with a new struct
    struct LineComponent
containing the 2 endpoints of the line:
    glm::vec2 pointA = { 0.0f, 0.0f };
    glm::vec2 pointB = { 0.0f, 0.0f };
but this time also containing the color:
    glm::vec4 color = { 1.0f, 1.0f, 1.0f, 1.0f };
(
    Decided to include the color in LineComponent but NOT in LineGeometryComponent,
    because LineGeometryComponent is a line's "geometry" only.
    It's supposed to be used with a material - normally a SolidColorMaterial
    would be appropriate for a line geometry, but who knows, there might be a use case
    of attaching another material to a line geometry, that's why I decided to keep
    the line's geometry separate from the material that can be attached, in the case of LineGeometryComponent.
    However, in the case of LineComponent, this is not a line's geometry anymore,
    it is the line itself - a line primitive. So it has color as part of its own definition.
)
and a new class
    class LineSystem
that has a single API for getting the vertex positions, same as all shape types until now:
    static void getVertexPositions
    (
        const entt::registry& registry,
        entt::entity entity,
        void* vertices,                // output array of vertices
        int vertexSize,                // size of a single vertex, in bytes
        int positionAttributeOffset    // offset from the start of each vertex to the position attribute, in bytes
    );
It works very similarly to the systems of all shape types,
but it does some things more directly, for example applying the tranform to the local vertex positions:
    const glm::vec2 verticesWorld[2] =
    {
        Utils2D::applyTransform(registry, transform, line.pointA),
        Utils2D::applyTransform(registry, transform, line.pointB)
    };
For that I created a new API in Utils2D
(
    by the way, renamed ShapeGeometryUtils to Utils2D
)
for directly applying a transform component to a local vertex position to get a world vertex position:
    static glm::vec2 applyTransform(const entt::registry& registry, const TransformComponent2D& transform, glm::vec2 localPosition);

Then, to render a line primitive I created a new function in Renderer2D_ECS.cpp:
    static void renderLine(const entt::registry& registry, entt::entity entity)
Again, it works very similarly to the render functions of shape types
but it does some things more directly.
And, importantly it renders the render object at the end with DrawMode::Lines :
    renderObject.render(DrawMode::Lines);
Nothing more to say there.

Tested it in Demo09.
Works fine.
Done.
}

{
Now looking at TO-DO item 0082
    Add support for parent-child hierarchies in TransformComponent2D and TransformSystem2D
I realized that it's already done.
When I integrated transforms in ECS I did the parent-child thingy and it works out of the box now.

Tested this in a new demo to make sure
    Demo10
This demo is all about transform hierarchies.

They work pretty well. Happy with that.
Done.
}

----------
16.11.2025
----------

{
Looked at TO-DO item 0071 today and yesterday.

Unfortunatelly we can't directly call
    RenderCommands::clear()
in PekanApplication's run() function because PekanApplication
is part of the Core module but RenderCommands is part of the Graphics module
and Core is not supposed to depend on Graphics.

The correct way to do this is to allow the Graphics subsystem to register
a callback in PekanApplication upon initialization
such that this callback is automatically called between frames by PekanApplication
but PekanApplication doesn't know what the callback is,
so that Core doesn't depend on Graphics.

We can implement a very general mechanism for this
that will probably be used for other things as well in the future.
We can implement a list of "on frame begin" callbacks
and a list of "on frame end" callbacks in PekanApplication
that are automatically called before/after a frame has been rendered.
Any code will be able to register a callback.
Once we have this mechanism we can let the Graphics subsystem
create a callback that clears the window and register that callback
as a "on frame begin" callback in PekanApplication so that it's
automatically called before every frame.
More specifically this can be done in GraphicsSystem's init() function.

So that's what I did.

PekanApplication now has these 2 private lists of callbacks:
    std::vector<OnFrameBeginCallback> m_onFrameBeginCallbacks;
    std::vector<OnFrameEndCallback> m_onFrameEndCallbacks;
and public APIs for registering a callback:
    void registerOnFrameBeginCallback(OnFrameBeginCallback callback);
    void registerOnFrameEndCallback(OnFrameEndCallback callback);
It also has these 2 private functions
    void callOnFrameBeginCallbacks();
    void callOnFrameEndCallbacks();
that just loop over the registered callbacks and call them.
These 2 functions should be called in the main loop in PekanApplication's run() function.
The question is where exactly.
The answer depends on what we consider to be "the frame".
That's kind of a subjective question, but I guess these 3 lines make sense
for me to be "the frame":
    updateRecurringCallbacks(float(deltaTime));
    m_layerStack.updateAll(deltaTime);
    m_layerStack.renderAll();
so I called the 2 functions callOnFrameBeginCallbacks() and callOnFrameEndCallbacks()
before and after those 3 lines.

That's it on the Core side of things.

Now that we have this general callbacks mechanism
let's use it to actually clear the window between frames.
In GraphicsSystem's init() function we need to first get the application pointer
    PekanApplication* application = PekanEngine::getApplication();
and check if it's not null.
Then we can register an "on frame begin" callback that clears the window:
    application->registerOnFrameBeginCallback
    (
        []()
        {
            RenderCommands::clear(true);
        }
    );
A thing that we can do before that is to set clear color to black,
just to make sure that the default is not something else:
    RenderState::setBackgroundColor(0.0f, 0.0f, 0.0f, 1.0f);
Also, how do we know if we need to clear the depth buffer as well?
(
    Calling only RenderCommands::clear(true) clears the color buffer only,
    and calling RenderCommands::clear(true, true) clears both the color buffer
    and the depth buffer.
)
Well we can just check if depth testing is enabled,
that's a good enough criteria for now.
So the lambda now becomes:
    []()
    {
        const bool isEnabledDepthTest = RenderState::isEnabledDepthTest();
        RenderCommands::clear(true, isEnabledDepthTest);
    }
One final thing that we need to do is to make this functionality optional.
Clearing the window between frames shouldn't always happen.
It should happen by default, but users should be able to disable it.
To do that I introduced a new flag in WindowProperties
    bool shouldClearAutomatically = true;
that is true by default.
We will use this flag in GraphicsSystem's init() function
to do registration of the callback only if the flag is enabled
    if (application->getProperties().windowProperties.shouldClearAutomatically)
    {
        RenderState::setBackgroundColor(0.0f, 0.0f, 0.0f, 1.0f);
        application->registerOnFrameBeginCallback(...);
    }

That's it.
Now window is automatically cleared between frames
unless user disables this by setting
    windowProperties.shouldClearAutomatically = false

It works!
Done.
}

----------
22.11.2025
----------

{
Let's look at TO-DO task 0078.

First such API that I see is
    getVertexPositions()
in
    LineSystem
However, this one is okay because it needs a registry, not just line data.
It needs the registry to retrieve transform's world matrix.
Even if it didn't, it needs the transform which is not part of line's data,
so it would still make sense that this API is part of the LineSystem
and NOT of the LineComponent.
So yeah, this one is fine.

Next such API that I see is
    getVertexColors
in
    SolidColorMaterialSystem
----------
10.12.2025
----------
Moved that one to
    SolidColorMaterialComponent
leaving SolidColorMaterialSystem empty so I removed it.
Looks good.

Next such APIs that I see are
    getPosition()
    getRotation()
    getScale()
    setPosition()
    setRotation()
    setScale()
    move()
    rotate()
    scale()
in
    TransformSystem2D
All of these APIs don't really need to be part of the system, they can be part of the component,
because they are related only to a single transform, they don't care about the transforms of other entities
or anything else in the scene.
The same is NOT true for
    getWorldMatrix()
There, we do, indeed, care for the transforms of other entities in the scene, because we need parent's world matrix.
So, we can safely keep getWorldMatrix() in the system.
We need to move all the rest to the component.
Did that.

----------
11.12.2025
----------

Next such API that I see is
    getNumberOfVertices()
in
    CircleGeometrySystem
We can easily move this to CircleGeometryComponent

Next such API that I see is
    getNumberOfVertices()
in
    PolygonGeometrySystem
Same thing, moving it to PolygonGeometryComponent

Next such APIs that I see are
    getWidth()
    getHeight()
    getSize()
    getTexture()
    getTextureCoordinatesMin()
    getTextureCoordinatesMax()
in
    SpriteSystem
These ones are not used at all, so literally just removing them.

Okay, seems that's all.
Looks good. Everything works as before but now we have cleaner ECS logic.
Done.
}

----------
12.12.2025
----------

{
Let's look at TO-DO task 0073.

Okay, looked at it, tried a few different things and ended up with this naming convention:
From now on we'll suffix subsystem classes with "Subsystem" instead of "System"
to differentiate them from ECS systems and to be extra clear that they are subsystems of Pekan.
Renamed
    Renderer2DSystem -> Renderer2DSubsystem
    GraphicsSystem -> GraphicsSubsystem
    GUISystem -> GUISubsystem
Also, decided ro rename
    Renderer2DSystem_ECS -> RenderSystem2D
This better matches other 2D ECS systems like CameraSystem2D, TransformSystem2D, etc.
and notice it's a "render" system, NOT a "renderer" system,
I think that makes more sense AND maybe more importantly it's different from Renderer2DSubsystem.
Looks good.

Done.
}

----------
13.12.2025
----------

{
Let's look at TO-DO task 0079.

Changed this line in CMakeLists.txt
    set(CMAKE_CXX_STANDARD 17)
to
    set(CMAKE_CXX_STANDARD 20)
Now all projects in our solution will use C++ 20.

And now that we have C++ 20 we can use designated initializers for this line:
    static constexpr CameraComponent2D g_defaultCamera = getDefaultCamera();
in
    CameraSystem2D.cpp
We can remove the getDefaultCamera() function and instead initialize g_defaultCamera like this:
    static constexpr CameraComponent2D g_defaultCamera =
    {
        .size = { 2.0f, 2.0f },
        .position = { 0.0f, 0.0f },
        .zoomLevel = 1.0f
    };
Did that. Looks good.

There are some build errors now due to the new C++ version.

Most notably constant strings that we define in a lot of places like this
    constexpr char* const vertexShaderFilePath = "resources/02_vertex_shader.glsl";
are a bit problematic, because "const" is after "*" which means that the pointer itself is const,
NOT the string that it points to, but a compile-time string like this HAS to be const,
so basically we need to move this "const" before the "*".
The pointer itself will still be const because the whole thing is constexpr.
So at the end we get this:
    constexpr const char* vertexShaderFilePath = "resources/02_vertex_shader.glsl";

Another build error that I had to fix was in a few places that had code like this:
    Utils2D::getWorldVertexPositions
    (
        registry,
        localVertexPositions.data(), localVertexPositions.size(),
        transform,
        VerticesAttributeView{ vertices, verticesCount, vertexSize, positionAttributeOffset }
    );
C++ 20 is complaining that this
    VerticesAttributeView{ vertices, verticesCount, vertexSize, positionAttributeOffset }
needs to be an lvalue because it's a non-const reference parameter.
Makes sense, although in our context this VerticesAttributeView is only a convenience struct,
what we really need to pass are these:
    vertices,
    verticesCount,
    vertexSize,
    positionAttributeOffset
and they ARE already lvalues, but still, we need their wrapper VerticesAttributeView to also be an lvalue.
Apparently C++ 17 allowed you to have a non-const reference to an rvalue but C++ 20 doesn't.
That's fine, we'll just create an lvalue, like this:
    VerticesAttributeView attributeView{ vertices, verticesCount, vertexSize, positionAttributeOffset };
    Utils2D::getWorldVertexPositions
    (
        registry,
        localVertexPositions.data(), localVertexPositions.size(),
        transform,
        attributeView
    );
The convenience of VerticesAttributeView is almost gone now, but I'll still keep it around.

That's it.
Build works now, and we use designated initializers to initialize g_defaultCamera in CameraSystem2D.cpp.
Done.
}

{
Looked at TO-DO task 0080,
but couldn't find any more appropriate places in code where a separate note would make things clearer.
Fixed some minor things though, in comments all around the code base.
Done.
}

----------
14.12.2025
----------

{
Let's look at TO-DO task 0081.

Yesterday I started work on this task, today I finished it.
There is now a new field in CameraComponent2D
    float rotation = 0.0f;
that controls camera's rotation.
Camera's rotation rotates the camera around its own center, as expected.
The way the maths works is the following:
- When going from world space to NDC we translate, rotate, scale
- When going from NDC to world space we scale, rotate, translate
Easier said than done, but that's basically it.
Nothing more to say about the maths. It was not easy to implement, but the core idea is simple.

Other than adding support for camera rotation I also added support for rotating the camera in CameraController2D.
Users can now rotate a camera by holding down the Alt key and using the Mouse Scroll.
Rotating is done around the mouse
and, also, made sure that panning works as expected with a rotated camera.

It works.
Done.
}

----------
15.12.2025
----------

{
Let's look at TO-DO task 0084:
    Think about rendering shapes/sprites/lines that don't have a transform.
    They can just be rendered in the default [-1, 1] range, it kind of makes sense.

This description doesn't really make sense.
What I meant to say when I was writing it is this:
1. Shapes/sprites/lines that don't have a transform can be rendered by just not applying a transform to their local vertices
2. If there is no camera in the scene, shapes/sprites/lines can still be rendered in the default [-1, 1] range
I will even change the TO-DO task to say this, instead of the old wrong description.

To test this I will create a sprite, a shape and a line that don't have a transform in Demo09.
Then we can actually modify engine code to render such entities.

----------
17.12.2025
----------

Okay, yesterday I finished the first part of this - rendering shapes/sprites/lines that don't have a transform.
Basic idea is the following:
1. We need to handle shapes/sprites/lines with a transform and shapes/sprites/lines without a transform separately.
    We need to separate the ones with a transform from the ones without a transform before passing them through the render pipeline.
    For example, this is how we get a view of all entities that have a SpriteComponent and a TransformComponent2D
        const auto view = registry.view<SpriteComponent, TransformComponent2D>();
    And this is how we can get a view of all entities that have a SpriteComponent and do NOT have a TransformComponent2D
        const auto view = registry.view<SpriteComponent>(entt::exclude<TransformComponent2D>);
    Until now we rendered sprites from the first view only, now we want to render sprites from the second one as well.
2. In order to render a shape/sprite/line without a transform we just need to use local vertex positions directly
    without applying a world matrix, because there is no world matrix when the entity doesn't have a transform.
    For that we need 2 versions of some of the functions in RenderSystem2D.cpp and SpriteSystem.cpp - one for entities with a transform,
    and one for entities without a transform.
    To make this easier and cleaner I decided to use template functions with a boolean parameter, for example:
        template<bool HasTransform>
        static void renderLineWithSolidColorMaterial(const entt::registry& registry, entt::entity entity);
    Then we have 2 different specializations of this function, one with HasTransform = true, and one with HasTransform = false:
        template<>
        static void renderLineWithSolidColorMaterial<true>(const entt::registry& registry, entt::entity entity)
        {
            ...
        }
        template<>
        static void renderLineWithSolidColorMaterial<false>(const entt::registry& registry, entt::entity entity)
        {
            ...
        }
    To facilitate this I created 2 versions of getVertexPositions() functions from shape systems, for example:
        static void getVertexPositionsLocal(...);
        static void getVertexPositionsWorld(...);
    in
        class CircleGeometrySystem
    The local one returns local vertex positions for an entity that may or may not have a transform.
    (We are using it exclusively on entities that don't have a transform, but the CircleGeometryComponent's API doesn't require this)
    And the world one returns world vertex positions for an entity that has a transform.
That's about it.
The way I implemented this is a bit random, because I'm not sure how final it is,
we may need to rewrite big parts of this code in the future. It works though, and is fairly easy to extend, so it's fine.

It works! Shapes/sprites/lines without a transform are rendered now.

----------
18.12.2025
----------

Now let's look at the second part of this task:
    If there is no camera in the scene, shapes/sprites/lines can still be rendered in the default [-1, 1] range
Turns out this already works.
It's done in this function
    CameraSystem2D::getPrimaryCamera()
If it doesn't find a camera marked as primary in the scene, it returns a default camera:
    return g_defaultCamera;
and this default camera has a size of {2, 2}, a position of {0, 0} and zoom level of 1,
which is exactly the [-1, 1] range in both X and Y.
I just removed the warning message that was getting printed if a camera is not found.
We don't need a warning message because we are considering it a valid use case.

Done.
}

{
Let's look at TO-DO task 0083:
    Think of an alternative to getMousePosition() from old Renderer2DSystem

Pretty straightforward actually.
First of all, Renderer2DSystem is now called Renderer2DSubsystem.
We still want getMousePosition() to be there in Renderer2DSubsystem,
it's just that we want it to use the primary camera from ECS instead of the one registered in Renderer2DSubsystem.
Registering a camera in Renderer2DSubsystem is the old way of doing things, we'll soon get rid of all that old stuff
and we'll leave only ECS.
For now, we can just create a new function with the same name but suffixed with "_ECS":
    getMousePosition_ECS()
Later, when we fully integrate ECS we will remove the other function and we'll rename this one, removing the "_ECS" suffix.
Now for the implementation of getMousePosition_ECS() it's really easy, it should do exactly the same as the old one
but instead of getting the camera from s_camera we'll get it like this:
    const CameraComponent2D& camera = CameraSystem2D::getPrimaryCamera(registry);
That's it. Then we get mouse position in window space, and convert to world space, same as before.

Tested it in Demo09 by setting rectangle's position to mouse position in the update() function
resulting in the rectangle following the mouse.
It works!

Done.
}

{
Let's do TO-DO task 0085:
    Rename GraphicsSystem's registerSubsystem() function to registerAsSubsystem().
    Same for other subsystems.

Sounds quite easy. Let's see.
Yep, just renamed GraphicsSubsystem's registerSubsystem(), GUISubsystem's registerSubsystem() and Renderer2DSubsystem's registerAsSubsystem()
functions to registerAsSubsystem().
Importantly, SubsystemManager's registerSubsystem() function is still called that, we will NOT rename it to registerAsSubsystem()
because it is the thing that registers a given subsystem,
and the other 3 are functions that register their own class AS A subsystem in SubsystemManager.

Done.
}

----------
19.12.2025
----------

{
Let's look at TO-DO task 0086:
    Think about
        return false;
    statements in PekanApplication's init() function.

Went through the code of PekanApplication::init() and PekanEngine::init().
There were a few small things that I fixed + added some error logging.
One of the things is this line
    m_isInitialized = true;
in PekanApplication::init()
It really has to be at the end, just before
    return true
Until now it was in the beginning so no matter if init() succeeded the flag m_isInitialized was marked as true.

That's about it. Other than that it looks good.

Done.
}

----------
26.12.2025
----------

{
No idea how I overlooked this but Pekan doesn't work at all with the current state of code.
More specifically, moving the
    m_isInitialized = true;
statement to the end of PekanApplication::init() breaks a few assertions down the road.
If you try to run Demo09 right now this assertion will fire:
    PK_ASSERT(isValid(), "Trying to register an event listener in a PekanApplication that is not yet initialized.", "Pekan");
in
    PekanApplication::registerEventListener()    (PekanApplication.cpp)
because CameraController2D is trying to register itself as an event listener in PekanApplication.
Here's the call stack:
    Demo09.exe!Pekan::PekanApplication::registerEventListener(const std::shared_ptr<Pekan::EventListener> & listener) Line 116	C++
    Demo09.exe!Pekan::Renderer2D::CameraController2D::init(Pekan::Renderer2D::Scene2D * scene) Line 35	C++
    Demo09.exe!Pekan::Renderer2D::Scene2D::init() Line 20	C++
    Demo09.exe!Pekan::LayerStack::initLayer(const std::shared_ptr<Pekan::Layer> & layer) Line 69	C++
    Demo09.exe!Pekan::LayerStack::initAll() Line 17	C++
    Demo09.exe!Pekan::PekanApplication::init() Line 41	C++

How can we solve this?
We can replace the m_isInitialized flag with an enum instead.
An enum that supports 3 values: not initialized, currently initializing, initialized
so that we can mark a PekanApplication as "currently initializing" during the executing of the init() function.

Done.
Added this enum class in PekanApplication:
    enum class InitState
    {
        NotInitialized,
        Initializing,
        Initialized
    };
and replaced the m_isInitialized flag with this variable of the enum type:
    InitState m_initState = InitState::NotInitialized;
Changed the assertions in some functions to check this
    m_initState != InitState::NotInitialized
instead of
    isValid()
Other functions still need to check
    isValid()
Basically for each function we need to ask ourselves if it makes sense to call this function during initialization.
If yes, then check
    m_initState != InitState::NotInitialized
If not, check
    isValid()

One more thing.
Obviously now that we have the enum we want to mark m_initState as Initializing
in the beggining of init() and mark m_initState as Initialized
at the end of init().
However, what do we do if init() fails halfway through?
We need to explicitly set m_initState to NotInitialized, because otherwise it will be left as Initializing
which is not good.
So, every time that we do an early out in init()
(it's always a "return false;" statement)
we need to also set m_initState to NotInitialized.
For example:
    if (!PekanEngine::init(this))
    {
        PK_LOG_ERROR("PekanEngine failed to initialize.", "Pekan");
        m_initState = InitState::NotInitialized;
        return false;
    }
That's about it. It works now.

Done.
}

{
Next TO-DO task is 0087:
    Why is application not terminated when user closes the window?

Found the bug, after ~1h of debugging.
Turns out the bug is deleting OpenGL resources after OpenGL context has been destroyed.
For example this line
    GLCall(glDeleteProgram(m_id));
in
    Shader::destroy()    (Shader.cpp)
is (not directly) called by
    SubsystemManager::exitAll();
in
    PekanEngine::exit()    (PekanEngine.cpp)
but before that PekanEngine::exit() calls
    s_window.destroy();
which destroys the OpenGL context.
So glDeleteProgram() is called when the OpenGL context is already destroyed.
OpenGL doesn't crash when this happens, it just hangs (it's undefined behavior, but on my machine it hangs).

Solution is quite simple, we just need to swap these 2 lines
    s_window.destroy();
    SubsystemManager::exitAll();
in PekanEngine::exit(), so it has to be like this:
    SubsystemManager::exitAll();
    s_window.destroy();
It makes sense. We first exit all subsystems, because they can be dependant on the window,
and then we destroy the window, which is definitely NOT dependant on subsystems.

That's it. This fixes Demo04 for example, but Demo10 still doesn't work.

Found out why Demo10 doesn't work. This time it's a bug in client code.
Client code doesn't destroy all entities in destroy(). It destroys m_body but it has to additionally destroy the other entities:
    m_scene->destroyEntity(m_leftArmJoint);
    m_scene->destroyEntity(m_leftArm);
    m_scene->destroyEntity(m_rightArmJoint);
    m_scene->destroyEntity(m_rightArm);
    m_scene->destroyEntity(m_leftLegJoint);
    m_scene->destroyEntity(m_leftLeg);
    m_scene->destroyEntity(m_rightLegJoint);
    m_scene->destroyEntity(m_rightLeg);
    m_scene->destroyEntity(m_head);
    m_scene->destroyEntity(m_sword);
Now it works. It closes fine.

----------
15.01.2026
----------

Demo09 doesn't close fine tho.
Why?

----------
17.01.2026
----------

Debugged it.
Found out the reason is PostProcessor.
More specifically, when an application uses PostProcessor this global RenderObject
    static RenderObject g_renderObject;
in
    PostProcessor.cpp
is created and then nothing destroys it explicitly.
OpenGL context is destroyed, and only after that this global variable g_renderObject
is destroyed (at the end of the main function), calling RenderObject's destructor
and hence Shader's destructor (and/or the destructor of other OpenGL primitives).
That's where code hangs, because OpenGL context is already destroyed but we try to delete an OpenGL primitive.

What we need to do is to properly exit PostProcessor in time, before destroying OpenGL context,
and make sure we destroy all created OpenGL-based global variables.
In PostProcessor.cpp these are the OpenGL-based global variables:
    static FrameBuffer g_frameBufferMultisample;
    static FrameBuffer g_frameBufferFinal;
    static RenderObject g_renderObject;
We need to make sure that all of them are properly destroyed upon exit.

Created a new function in PostProcessor
    static void exit();
Made it private, because only GraphicsSubsystem will be able to call it.
For that, of course, I also made GraphicsSubsystem be a friend to PostProcessor.
Then we just need to call
    PostProcessor::exit();
in
    GraphicsSubsystem::exit()
That's it.
Demo09 closes fine now.

----------
18.01.2026
----------

Demo08 doesn't close correctly.
Why?

I actually found 2 distinct reasons.
1. In Demo08_Scene's exit() function we were missing this:
        for (int i = 0; i < m_animTextures.size(); i++)
        {
            m_animTextures[i]->destroy();
        }
    Explicitly destroying the animation textures.
    If we don't do that, this vector of texture pointers will be freed only after the end of the main function,
    which as we already know leads to dangling OpenGL resources and hanging.
2. In class Sprite we have this member
        Graphics::Texture2D_ConstPtr m_texture;
    It holds a shared pointer to the underlying texture (an OpenGL resource)
    When a Sprite instance's destroy() function is called, nothing happens to this m_texture pointer.
    It remains intact, still holding onto the texture, so the texure itself is not destroyed.
    After the main function is finished, that's when Sprite's actual destructor is called,
    and that's when m_texture is freed, but it's too late because the OpenGL context is already destroyed.
    Solution is really simple, just set m_texture to null in Sprite's destroy() function:
        m_texture = nullptr;
    That way, the m_texture pointer no longer hold onto the underlying texture resource and so it can destroy itself.
    (If there are no other pointers referencing it, of course).
That's it.
Demo09 closes correctly now.

That's all the demos closing correctly now.

Done.
}

{
Looked at TO-DO task 0088.

Looks like we can't actually use view in any of our cases. Keep it in mind for the future tho, but in current code it's already good.

Done.
}

----------
19.01.2026
----------

{
Let's look at TO-DO task 0089.

Added a post-build command in each demo's CMake file (except Demo05 and Demo07, they don't have any resources)
that copies the resources/assets/Shaders folder to the build folder so that each demo's .exe can access resources
by relative path.

----------
19.01.2026
----------

Regenerated and built all demos.
Tried running each demo using its .exe file, in both Debug and Release mode.
Seems to work fine.

Done.
}

{
Today I did TO-DO task 0090.

Updated
    gen.bat
script to pass along options in this format "-DOPTION=VALUE" or "-DOPTION VALUE" to CMake.
So now the script can be used, for example, to set this CMake option
    WITH_DEMO_PROJECTS
to OFF when invoking the CMake command and generating the Visual Studio solution.
That's how it would be done:
    gen.bat -DWITH_DEMO_PROJECTS=OFF
or
    gen.bat -DWITH_DEMO_PROJECTS OFF
That's it.

Tested a few different scenarios.
It works.

(
    While testing I noticed a small bug.
    Build is broken if PEKAN_ENABLE_2D_SHAPES_ORIENTATION_CHECKING option is ON.
    It fails to build because of this line
        if (MathUtils::isOrientationReversedByTransform(transformMatrix) != m_isReversedIndices)
    in
        PolygonShape.cpp    ( in updateVerticesWorld() )
    This "transformMatrix" there should be "worldMatrix", like this:
        if (MathUtils::isOrientationReversedByTransform(worldMatrix) != m_isReversedIndices)
    Recently we renamed "transformMatrix" to "worldMatrix" in this function
    and apparently we forgot to change it on this line.
    Fixed.
)

Done.
}

----------
23.01.2026
----------

{
All TO-DO tasks are done now, except for optimization ones.
It's a good idea to leave those for a bit later,
as to not write a bunch of code that will be overwritten later.

It's time to remove old shape classes and old sprite class,
and any other old code that is now obsolete because of ECS.

----------
28.01.2026
----------

Removed all obsoleted code.
A bunch of files like
    Sprite.h
    Sprite.cpp
    Shape.h
    Shape.cpp
    RectangleShape.h
    RectangleShape.cpp
    Transformable2D.h
    Transformable2D.cpp
    etc.
together with all places where they are referenced.

Demo09 and Demo10 build and run properly,
because they are built on new ECS code only.

Demo00, Demo01, Demo02 and Demo03 also build and run properly,
because they are built on the Graphics module only, not using anythin from Renderer2D.

Demo04, Demo05, Demo06, Demo07 and Demo08 fail to build currently,
because they use old non-ECS code from Renderer2D (shape classes and sprite class mostly)
We'll have to rewrite those demos to use the new ECS API.

    {
    Integrated ECS in Demo08 today, but it doesn't fully work.
    There is a missing feature in Pekan's ECS to make Demo08 work as it did before.
    Namely, once we have all the sprites in a vector there is no way to render only a part of them.
    We need to render only a part of them because GUI controls how many of them need to be rendered.
    Currently there is no way to do that because if a sprite exists in the registry then the sprite will be rendered,
    client code has no control over that.

    To fix that we need a mechanism for disabling an entity.
    The simplest and best for performance solution is to have a
        DisabledComponent
    component that can be added to any entity to disable it.
    Then all systems would have to ignore entities that have a DisabledComponent on them.

    Sounds good, let's do it.
    Created a file
        DisabledComponent.h
    under a new directory Entity, here:
        src/Core/Entity
    We literally don't need anything in DisabledComponent, just an empty struct:
        struct DisabledComponent
        {};
    The only information that a DisabledComponent carries is the fact that it exists and is assigned to an entity.
    Then, we need to modify all existing systems that get a view from a registry,
    to exclude entities that have a DisabledComponent, for example in CameraSystem2D.cpp we have this line:
        const auto view = registry.view<CameraComponent2D>();
    for getting a view of all entities that have a CameraComponent2D.
    We need to change it to:
        const auto view = registry.view<CameraComponent2D>(entt::exclude<DisabledComponent>);
    Now it's getting a view of all entities that have a CameraComponent2D and do NOT have a DisabledComponent.
    Do this in all other places where we get a view from a registry.
    That's it.

    Now, in Demo08, in updateSprites() we can add DisabledComponent to these sprites:
        for (size_t i = m_spritesCount; i < m_spritesMaxCount; i++)
    And, we also need to make sure that these sprites
        for (int i = 0; i < m_spritesCount; i++)
    don't have a DisabledComponent.
    It works now.

    Done.
    }

----------
29.01.2026
----------

    {
    Integrated ECS in Demo07 today.
        (
        A thing worth mentioning is that I removed the "static circle" from the demo,
        because we currently don't have static circles, we have only one type of circle.
        Not sure if we'll have static circles in the future.
        ("static" as in having a fixed number of vertices and allocating that memory on the stack if possible)
        )
    It works.
    Done.
    }

----------
30.01.2026
----------

    {
    Integrated ECS in Demo05 today.
    Pretty easy, nothing to say.
    It works.
    Done.
    }

----------
31.01.2026
----------

    {
    Integrated ECS in Demo06 today and yesterday.
    It was a bit tricky to set DisabledComponent correctly on all shape types,
    and do it only when there is an update in GUI.
    It's nothing to do with engine functionality though, just app-specific logic.
    It works.
    Done.
    }

----------
02.02.2026
----------

    {
    Integrated ECS in Demo04 today and yesterday.
    There was a slight issue - the demo contains both 2D entities and a RenderObject
    which is part of Graphics, NOT of Renderer2D, it's also not part of ECS yet.
    Luckily our Scene2D supports additional render steps by overriding the _render() function,
    so that's what I did - manually rendered the RenderObject in _render().
    Not sure if that's a good solution in general, created TO-DO tasks for this. For now Demo04 is fine like that.

    Another problem is that there is no way to specify the order of rendering of the RenderObject and the 2D shapes.
    Right now, the additional render steps from _render() are done AFTER the ECS rendering of shapes,
    so the RenderObject is drawn on top of the shapes, which is NOT what we want,
    but currently there is no way to fix that. Created a TO-DO task for that as well.

    Considering ECS integrated in Demo04 for now, with some things to fix after completing the TO-DO tasks.
    Done.
    }

----------
03.02.2026
----------

Removed unused shaders (shaders that were used in old obsoleted code).

That's all, I think.
All demos work.
The whole solution builds okay.
Done.
}

----------
04.02.2026
----------

{
A small thing that I want to do before continuing:
Let's rename some things in the Graphics module to make them clearer in the context of current architecture,
and to not clash with ECS terminology.

First, let's rename this directory
    RenderComponents
to
    GpuResources
That's more accurate and clearer, and can't be confused with ECS components.
Done.

Second, let's rename this class
    class RenderObject
to
    class DrawObject
It's more accurate because it's an object containing a bunch of GPU resources needed for a draw call,
and we don't want to confuse it with Renderer2D, it is NOT part of Renderer2D, it's part of Graphics.
Done.
}

----------
05.02.2026
----------

{
Let's look at TO-DO task 0096:
    Think about creating a RenderObjectComponent in the Graphics module, or something similar.

It might not be a good idea to directly translate DrawObject to DrawObjectComponent in ECS.
Instead let's create
    struct RenderSourceComponent
that is a pure-ECS component, containing vertex data, index data, shaders, textures, etc.
Then also create
    class RenderSourceSystem
that will just render all entities with RenderSourceComponent
by creating underlying DrawObject's.
(Later we'll optimize this with batching, same way we did for shapes before, in v0.2)

Srtarted doing that, but it doesn't seem very promising.
I have this so far:
    struct RenderSourceComponent
    {
        std::vector<uint8_t> vertexData;
        VertexBufferLayout vertexBufferLayout;
    };
but I really don't like this VertexBufferLayout member.
How can we do it without it though?
Should we have a pure-data equivalent of VertexBufferLayout?
Really not sure about this.

Let's leave this for later when we have and an editor with GUI ECS, and scene file export,
then it will be much clearer what we need from this RenderSourceComponent.
For now we can leave things as they are - users will have no direct way of creating custom render sources.
They can, of course, still create DrawObject's manually and render them in a render() function, that's fine.
But it will not be supported in ECS for now.
Better keep ECS simple for now, until we build the base of the editor and the scene file export.

Considering this task done, although we did nothing.
I'll create a new TO-DO task with better description taking into account the conclusions that I got today.

Done.
}

----------
06.02.2026
----------

{
Let's do TO-DO task 0091.
Sounds simple.

Okay, did it.
Added this global static variable
    static const CameraComponent2D* g_camera = nullptr;
in
    RenderSystem2D.cpp
that we'll use to cache the camera in the beginning of
    RenderSystem2D::render()
so that every function in this file can easily use the camera, without retrieving it from CameraSystem2D anew each time.

NOTE: This makes RenderSystem2D::render() non-thread-safe.
It's kind of a temporary solution anyway, because we will heavily rewrite RenderSystem2D and SpriteSystem soon
when we introduce batching.

We need the same thing in SpriteSystem - global static variable
    static const CameraComponent2D* g_camera = nullptr;
in
    SpriteSystem.cpp
The difference is that we don't want to call
    CameraSystem2D::getPrimaryCamera()
in SpriteSystem, because we already call it in RenderSystem2D::render().
We can just pass along the camera from RenderSystem2D::render() to SpriteSystem::render(),
so let's change SpriteSystem::render()'s signature:
    static void render(const entt::registry& registry, const CameraComponent2D* camera);
to take in a camera pointer.
That's it.

It works same as before, but now we call
    CameraSystem2D::getPrimaryCamera()
only once per frame.

Done.
}

{
Let's do TO-DO task 0092.

Solution here is quite simple.
The variable
    CMAKE_SOURCE_DIR
is problematic because it points to the source directory of whatever the main project is in the current build.
What we want instead is the source directory of Pekan, no matter what the main project is.
We can get that from this variable:
    CMAKE_CURRENT_SOURCE_DIR

We already use that variable when setting PEKAN_ROOT_DIR, on this line:
    target_compile_definitions(Core PRIVATE PEKAN_ROOT_DIR="${CMAKE_CURRENT_SOURCE_DIR}")
so yeah, just use that for entt as well.

Done.
}

{
Let's do TO-DO task 0093.

Did it. Easy.
Also added comments to move(), rotate() and scale() functions in TransformComponent2D.h
to make it clear that move() and rotate() are adding the deltaPosition and deltaRotation
and scale() is multiplying by the deltaScale.

scale() is not used anywhere (i checked) so nothing to test really.

Done.
}

{
Let's look at TO-DO task 0094.

Went through all calls to DrawObject's
    setIndexData()
and, indeed, there were a few that had to have
    BufferDataUsage::StaticDraw
but didn't.
Fixed them.

Also checked all calls to DrawObject's
    setVertexData()
(it has the same buffer usage logic)
They were fine, nothing to change there.

Build is fine.
Everything works as before.
Done.
}

----------
07.02.2026
----------

{
Let's do TO-DO task 0095.

Created 2 functions in class Scene:
    void enableEntity(entt::entity entity);
    void disableEntity(entt::entity entity);
They just add/remove DisabledComponent from given entity and first check if entity already has DisabledComponent.
Used these 2 functions in all demos where DisabledComponent was directly used.
They work same as before, but code is simpler.

Done.
}

{
Let's do TO-DO task 0100.

Decided to use tabs for identation,
and spaces for visual clarity.

Replaced all "    " (consecutive 4 spaces)
that are used for identation
with "	" (a tab).
Went through them manually, made sure a tab makes sense for each one.

Kept "    " (consecutive 4 spaces)
in places that intentionally use spaces for visual clarity (lining up stuff mostly).

Basic rule of thumb:
    If 4 spaces are seen in the beginning of a line, they should be a tab.
    If 4 spaces are seen in the middle of a line, or in a comment, they are ok.

There were also a few shaders that use 3 spaces for indentation.
There I replaced 3 spaces with a tab.

That's it.
Now we use tabs and spaces consistenly in all files.
No other changes were made, everything works as before.

Done.
}

----------
09.02.2026
----------

With that, the Entity Component System is done (more or less).
At least functionally it covers everything that could be done before we started integrating it.

There are 7 TO-DO tasks left to do,
but I'll leave them for later, because they kind of depend on the next stages
and are not needed for the next stages,
so it's better to do them later.

{
Next stage in Pekan's development is very essential - the Editor.

It's a good moment to start implementing the Editor now
because we have a functioning ECS
and we need to know how the Editor will look, what it will need from other modules,
what the architecture around it will be,
we need to know all those things to be able to continue adequately.
Also, the Editor will be a good testing ground for future features,
it will allow for quicker and more flexible testing,
compared to the current approach, which is to create specific demo projects to test specific features.

First step is to create a new module
    Editor

It will start off as any other application made in Pekan.
I just copied Demo10, deleted all of its contents and renamed it to Editor.
That's it.
That's the skeleton of Editor that we'll start with.
}

{
Next step.
We actually need 2 GUIWindow's for the Editor,
- one for the list of entities
- another for the properties of a specific entity

First GUIWindow is called
    EntitiesGUIWindow
Let's call the second one
    EntityPropertiesGUIWindow

Hmm did it, but it doesn't work.
Only the first GUIWindow appears when you run the Editor.
Seems like that's a bug in Pekan - multiple GUIWindow's don't work at all.
Created a TO-DO task for that:
    0102
}

----------
10.02.2026
----------

{
Let's do TO-DO task 0102 before we continue with Editor,
because we definitely need 2 GUI windows in Editor and currently there's no way to do that.

We basically need to separate the code in GUIWindow::render()
so that this part
    ImGui_ImplOpenGL3_NewFrame();
    ImGui_ImplGlfw_NewFrame();
    ImGui::NewFrame();
happens once at the beginning of every frame, before rendering the potentially multiple GUI windows
and this part
    ImGui::Render();
    ImGui_ImplOpenGL3_RenderDrawData(ImGui::GetDrawData());
    // Update and Render additional Platform Windows
    // (Platform functions may change the current OpenGL context, so we save/restore it)
    if (ImGui::GetIO().ConfigFlags & ImGuiConfigFlags_ViewportsEnable)
    {
        GLFWwindow* backup_current_context = glfwGetCurrentContext();
        ImGui::UpdatePlatformWindows();
        ImGui::RenderPlatformWindowsDefault();
        glfwMakeContextCurrent(backup_current_context);
    }
happens once at the end of every frame, after rendering the potentially multiple GUI windows.
The rest of the code we'll leave in GUIWindow::render() because it is what actually renders a single GUI window.

So how do we make the 2 parts happen at the beginning and end of every frame?
Easy, we already have the registerOnFrameBeginCallback/registerOnFrameEndCallback mechanism in PekanApplication,
we just need to register 2 functions that do the 2 parts above.
A good place to do that is in GUISubsystem.
Let's create 2 new static private functions there:
    static void beginFrame();
    static void endFrame();
They will be the 2 functions that we will register in PekanApplication to be called at the beginning and end of each frame.
The registration itself can be done in GUISubsystem's init() function:
    application->registerOnFrameBeginCallback([]() { GUISubsystem::beginFrame(); });
    application->registerOnFrameEndCallback([]() { GUISubsystem::endFrame(); });
Then, we'll implement the 2 functions by just pasting the 2 parts of the old GUIWindow::render() (mentioned above).

One more thing, just as a sanity check and for easier error handling let's add this flag
    inline static bool m_isFrameActive = false;
in GUISubsystem, that we'll use to keep track if an ImGui frame is currently active.
beginFrame() creates and activates an ImGui frame and it remains active until endFrame() is called.
In the beginning of beginFrame() and endFrame() we can check if m_isFrameActive is what we expect it to be
just to make sure that we don't try to call beginFrame() when a frame is already active or endFrame() when no frame is currently active.

That's it.
Editor works now, both GUI windows appear. Looks good.

Done.
}

{
Next step for Editor would be to add a "+" button in
    EntitiesGUIWindow
When clicked it will add a new entity to the scene.
Here's the button, as a new member in EntitiesGUIWindow's Widgets:
    Pekan::GUI::ButtonWidget_Ptr addEntityButtonWidget = std::make_shared<Pekan::GUI::ButtonWidget>();
Then in EntitiesGUIWindow::update() we can do that:
    if (gui.addEntityButtonWidget->isClicked() && m_scene != nullptr)
    {
        // ...
    }
to detect when the button is clicked.
What do we do when it's clicked?
We need to add an entity to the scene.
For that, let's have a pointer to the scene as a member in EntitiesGUIWindow:
    std::shared_ptr<EditorScene> m_scene;
together with a setter function:
    void setScene(std::shared_ptr<EditorScene> scene) { m_scene = scene; }
Then, in EditorApplication's _fillLayerStack() we can call the setter and set the scene:
    entitiesGuiWindow->setScene(scene.get());
Okay, now we have access to the scene from EntitiesGUIWindow.
To actually add an entity to the scene, we'll need a new public function on EditorScene:
    void addEntity();
To implement this function we'll need to create an entity in the scene:
    entt::entity entity = createEntity();
but also we need to keep track of all created entities, so let's have a new member in EditorScene:
    std::vector<entt::entity> m_entities;
which will be just a list of all created entities (Remember that entt::entity is just an integer - the entity's ID)
Then, in addEntity() we'll need to also add the created entity to the list of entities:
    m_entities.push_back(entity);
That's all for addEntity().
Now we can easily just call addEntity() from EntitiesGUIWindow if the button is clicked:
    if (gui.addEntityButtonWidget->isClicked() && m_scene != nullptr)
    {
        m_scene->addEntity();
    }

That was the easy part.
Now we need to also display the list of entities in EntitiesGUIWindow.
We don't have a list widget in our GUI module yet, I created a TO-DO task for that.
For now we can just override the _render() function and implement what we need directly with ImGui.
First, we'll need to actually get the list of entities from the scene.
For that, create a getter in EditorScene:
    const std::vector<entt::entity>& getEntities() const { return m_entities; }
and call it in EntitiesGUIWindow::_render():
    const std::vector<entt::entity>& entities = m_scene->getEntities();
To display entities in a list widget with selectable elements we need to loop over entities:
    for (const auto& entity : entities)
and call
    ImGui::Selectable(const char* label, ...)
for each one.
The way it works is if you call ImGui::Selectable() multiple times in a row
it will just put multiple "selectable" widgets one after the other, like a list
(not technically a list, they are just independent widgets one after the other)
So, for each entity we can form a string using entity's ID:
    const std::string entityLabel = "Entity " + std::to_string(static_cast<uint32_t>(entity));
and this will be the label that we pass to ImGui::Selectable:
    ImGui::Selectable(entityLabel.c_str());
This works for displaying a list of entities in the scene.

----------
11.02.2026
----------

However, selecting doesn't work properly yet.
We need to somehow keep track of which entity is selected and which entities are NOT selected.
We need to do that manually, because ImGui is an immediate-GUI type of framework
and the way it works is that this
    ImGui::Selectable()
function is a completely stateless call.
Every frame we call it however we like, it doesn't have any sense of its own state.
We have to maintain its state manually in our code.
So, the thing we can do is to keep track of which entity is currently selected.
To do that, let's have a member variable in EntitiesGUIWindow:
    mutable entt::entity m_selectedEntity = entt::null;
Then, when we call ImGui::Selectable() we need to pass it a second argument:
    ImGui::Selectable(const char* label, bool selected, ...)
which is a boolean indicating the current "selected" state of the selectable widget.
The meaning of "current" here is a bit confusing.
Whatever "selected" state we pass it that's how it's going to render the widget right now, on this frame.
(if we pass true it will render a selected widget, if we pass false it will render an unselected widget)
We can calculate the "selected" state by just comparing the current entity in the for loop with the currently selected one:
    const bool isSelected = (entity == m_selectedEntity);
then we pass that boolean to ImGui::Selectable, like this:
    ImGui::Selectable(entityLabel.c_str(), isSelected)
The return value of ImGui::Selectable() is also a boolean and it indicates whether user is clicking the widget right now.
So if it returns true we need to mark the entity as selected:
    if (ImGui::Selectable(entityLabel.c_str(), isSelected))
    {
        m_selectedEntity = entity;
    }
Once we mark it as selected it will be rendered as selected from now on, thanks to our isSelected parameter.
That's it for EntitiesGUIWindow::_render().
It now correctly renders the list of entities and user can select an entity, and we keep track of the currently selected entity.
Great!

One last thing.
We'll need to access the currently selected entity in the other GUI window - EntityPropertiesGUIWindow.
Let's create the mechanism for doing so now.
I think what makes most sense is to have a pointer to the EntitiesGUIWindow inside EntityPropertiesGUIWindow
    std::shared_ptr<EntitiesGUIWindow> m_entitiesGUIWindow;
Same way we have a pointer to the scene.
We'll think about maybe decoupling the 2 GUI windows in the future and have a central place of control maybe, but for now it's good.
For now it totally makes sense that the EntityPropertiesGUIWindow depends on EntitiesGUIWindow,
because it needs to know what the currently selected entity is.
Okay.
Together with that pointer we'll need a setter, of course:
    void setEntitiesGUIWindow(std::shared_ptr<EntitiesGUIWindow> entitiesGUIWindow) { m_entitiesGUIWindow = entitiesGUIWindow; }
Same way as for the scene.
Then, we'll make sure to properly set the EntitiesGUIWindow calling this setter in EditorApplication:
    entityPropertiesGuiWindow->setEntitiesGUIWindow(entitiesGuiWindow);
Now EntityPropertiesGUIWindow can access EntitiesGUIWindow.
What it needs is an API for getting the currently selected entity.
We just need a simple getter for the selected entity in EntitesGUIWindow:
    entt::entity getSelectedEntity() const { return m_selectedEntity; }
Then, in EntityPropertiesGUIWindow::_render() we can get the currently selected entity, like this:
    const entt::entity selectedEntity = m_entitiesGUIWindow->getSelectedEntity();
And we can just show it as text for now:
    ImGui::Text("Selected Entity: %u", static_cast<uint32_t>(selectedEntity));
If there is no selected entity we can show "No entity selected":
    if (selectedEntity == entt::null)
    {
        ImGui::Text("No entity selected");
        return;
    }
Not sure if we'll keep this part like this, but for now it's perfectly good for testing.
That's it.

It works!
We can add entities to the scene by clicking the button in EntitiesGUIWindow.
They appear in a list there, and we can select an entity.
The selected entity appears in EntityPropertiesGUIWindow.
}
